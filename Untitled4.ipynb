{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8e8e6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U deepeval -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12a1acb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers torch -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ee0de61",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/75/35/07c9879163b603f0e464b0f6e6e628a2340cfc7cdc5ca8e7d52d776710d4/transformers-4.44.2-py3-none-any.whl.metadata\n",
      "  Using cached transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\sahil\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Using cached transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "Installing collected packages: transformers\n",
      "Successfully installed transformers-4.44.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bd8a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install  --upgrade pillow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb88263a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ALBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'ALIGN_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ALIGN_PRETRAINED_MODEL_ARCHIVE_LIST', 'ALL_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ALTCLIP_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ALTCLIP_PRETRAINED_MODEL_ARCHIVE_LIST', 'ASTConfig', 'ASTFeatureExtractor', 'ASTForAudioClassification', 'ASTModel', 'ASTPreTrainedModel', 'AUDIO_SPECTROGRAM_TRANSFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'AUDIO_SPECTROGRAM_TRANSFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'AUTOFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'AUTOFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'Adafactor', 'AdamW', 'AdamWeightDecay', 'AdaptiveEmbedding', 'AddedToken', 'Agent', 'AlbertConfig', 'AlbertForMaskedLM', 'AlbertForMultipleChoice', 'AlbertForPreTraining', 'AlbertForQuestionAnswering', 'AlbertForSequenceClassification', 'AlbertForTokenClassification', 'AlbertModel', 'AlbertPreTrainedModel', 'AlbertTokenizer', 'AlbertTokenizerFast', 'AlignConfig', 'AlignModel', 'AlignPreTrainedModel', 'AlignProcessor', 'AlignTextConfig', 'AlignTextModel', 'AlignVisionConfig', 'AlignVisionModel', 'AltCLIPConfig', 'AltCLIPModel', 'AltCLIPPreTrainedModel', 'AltCLIPProcessor', 'AltCLIPTextConfig', 'AltCLIPTextModel', 'AltCLIPVisionConfig', 'AltCLIPVisionModel', 'AlternatingCodebooksLogitsProcessor', 'AqlmConfig', 'AudioClassificationPipeline', 'AutoBackbone', 'AutoConfig', 'AutoFeatureExtractor', 'AutoImageProcessor', 'AutoModel', 'AutoModelForAudioClassification', 'AutoModelForAudioFrameClassification', 'AutoModelForAudioXVector', 'AutoModelForCTC', 'AutoModelForCausalLM', 'AutoModelForDepthEstimation', 'AutoModelForDocumentQuestionAnswering', 'AutoModelForImageClassification', 'AutoModelForImageSegmentation', 'AutoModelForImageToImage', 'AutoModelForInstanceSegmentation', 'AutoModelForMaskGeneration', 'AutoModelForMaskedImageModeling', 'AutoModelForMaskedLM', 'AutoModelForMultipleChoice', 'AutoModelForNextSentencePrediction', 'AutoModelForObjectDetection', 'AutoModelForPreTraining', 'AutoModelForQuestionAnswering', 'AutoModelForSemanticSegmentation', 'AutoModelForSeq2SeqLM', 'AutoModelForSequenceClassification', 'AutoModelForSpeechSeq2Seq', 'AutoModelForTableQuestionAnswering', 'AutoModelForTextEncoding', 'AutoModelForTextToSpectrogram', 'AutoModelForTextToWaveform', 'AutoModelForTokenClassification', 'AutoModelForUniversalSegmentation', 'AutoModelForVideoClassification', 'AutoModelForVision2Seq', 'AutoModelForVisualQuestionAnswering', 'AutoModelForZeroShotImageClassification', 'AutoModelForZeroShotObjectDetection', 'AutoModelWithLMHead', 'AutoProcessor', 'AutoTokenizer', 'AutoformerConfig', 'AutoformerForPrediction', 'AutoformerModel', 'AutoformerPreTrainedModel', 'AutomaticSpeechRecognitionPipeline', 'AwqConfig', 'AzureOpenAiAgent', 'BARK_PRETRAINED_MODEL_ARCHIVE_LIST', 'BART_PRETRAINED_MODEL_ARCHIVE_LIST', 'BEIT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BEIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'BERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'BIGBIRD_PEGASUS_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BIGBIRD_PEGASUS_PRETRAINED_MODEL_ARCHIVE_LIST', 'BIG_BIRD_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BIG_BIRD_PRETRAINED_MODEL_ARCHIVE_LIST', 'BIOGPT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BIOGPT_PRETRAINED_MODEL_ARCHIVE_LIST', 'BIT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'BLENDERBOT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BLENDERBOT_PRETRAINED_MODEL_ARCHIVE_LIST', 'BLENDERBOT_SMALL_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BLENDERBOT_SMALL_PRETRAINED_MODEL_ARCHIVE_LIST', 'BLIP_2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BLIP_2_PRETRAINED_MODEL_ARCHIVE_LIST', 'BLIP_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BLIP_PRETRAINED_MODEL_ARCHIVE_LIST', 'BLOOM_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BLOOM_PRETRAINED_MODEL_ARCHIVE_LIST', 'BRIDGETOWER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BRIDGETOWER_PRETRAINED_MODEL_ARCHIVE_LIST', 'BROS_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BROS_PRETRAINED_MODEL_ARCHIVE_LIST', 'BarkCausalModel', 'BarkCoarseConfig', 'BarkCoarseModel', 'BarkConfig', 'BarkFineConfig', 'BarkFineModel', 'BarkModel', 'BarkPreTrainedModel', 'BarkProcessor', 'BarkSemanticConfig', 'BarkSemanticModel', 'BartConfig', 'BartForCausalLM', 'BartForConditionalGeneration', 'BartForQuestionAnswering', 'BartForSequenceClassification', 'BartModel', 'BartPreTrainedModel', 'BartPretrainedModel', 'BartTokenizer', 'BartTokenizerFast', 'BarthezTokenizer', 'BarthezTokenizerFast', 'BartphoTokenizer', 'BasicTokenizer', 'BatchEncoding', 'BatchFeature', 'BeamScorer', 'BeamSearchScorer', 'BeitBackbone', 'BeitConfig', 'BeitFeatureExtractor', 'BeitForImageClassification', 'BeitForMaskedImageModeling', 'BeitForSemanticSegmentation', 'BeitImageProcessor', 'BeitModel', 'BeitPreTrainedModel', 'BertConfig', 'BertForMaskedLM', 'BertForMultipleChoice', 'BertForNextSentencePrediction', 'BertForPreTraining', 'BertForQuestionAnswering', 'BertForSequenceClassification', 'BertForTokenClassification', 'BertGenerationConfig', 'BertGenerationDecoder', 'BertGenerationEncoder', 'BertGenerationPreTrainedModel', 'BertGenerationTokenizer', 'BertJapaneseTokenizer', 'BertLMHeadModel', 'BertLayer', 'BertModel', 'BertPreTrainedModel', 'BertTokenizer', 'BertTokenizerFast', 'BertweetTokenizer', 'BigBirdConfig', 'BigBirdForCausalLM', 'BigBirdForMaskedLM', 'BigBirdForMultipleChoice', 'BigBirdForPreTraining', 'BigBirdForQuestionAnswering', 'BigBirdForSequenceClassification', 'BigBirdForTokenClassification', 'BigBirdLayer', 'BigBirdModel', 'BigBirdPegasusConfig', 'BigBirdPegasusForCausalLM', 'BigBirdPegasusForConditionalGeneration', 'BigBirdPegasusForQuestionAnswering', 'BigBirdPegasusForSequenceClassification', 'BigBirdPegasusModel', 'BigBirdPegasusPreTrainedModel', 'BigBirdPreTrainedModel', 'BigBirdTokenizer', 'BigBirdTokenizerFast', 'BioGptConfig', 'BioGptForCausalLM', 'BioGptForSequenceClassification', 'BioGptForTokenClassification', 'BioGptModel', 'BioGptPreTrainedModel', 'BioGptTokenizer', 'BitBackbone', 'BitConfig', 'BitForImageClassification', 'BitImageProcessor', 'BitModel', 'BitPreTrainedModel', 'BitsAndBytesConfig', 'BlenderbotConfig', 'BlenderbotForCausalLM', 'BlenderbotForConditionalGeneration', 'BlenderbotModel', 'BlenderbotPreTrainedModel', 'BlenderbotSmallConfig', 'BlenderbotSmallForCausalLM', 'BlenderbotSmallForConditionalGeneration', 'BlenderbotSmallModel', 'BlenderbotSmallPreTrainedModel', 'BlenderbotSmallTokenizer', 'BlenderbotSmallTokenizerFast', 'BlenderbotTokenizer', 'BlenderbotTokenizerFast', 'Blip2Config', 'Blip2ForConditionalGeneration', 'Blip2Model', 'Blip2PreTrainedModel', 'Blip2Processor', 'Blip2QFormerConfig', 'Blip2QFormerModel', 'Blip2VisionConfig', 'Blip2VisionModel', 'BlipConfig', 'BlipForConditionalGeneration', 'BlipForImageTextRetrieval', 'BlipForQuestionAnswering', 'BlipImageProcessor', 'BlipModel', 'BlipPreTrainedModel', 'BlipProcessor', 'BlipTextConfig', 'BlipTextModel', 'BlipVisionConfig', 'BlipVisionModel', 'BloomConfig', 'BloomForCausalLM', 'BloomForQuestionAnswering', 'BloomForSequenceClassification', 'BloomForTokenClassification', 'BloomModel', 'BloomPreTrainedModel', 'BloomTokenizerFast', 'BridgeTowerConfig', 'BridgeTowerForContrastiveLearning', 'BridgeTowerForImageAndTextRetrieval', 'BridgeTowerForMaskedLM', 'BridgeTowerImageProcessor', 'BridgeTowerModel', 'BridgeTowerPreTrainedModel', 'BridgeTowerProcessor', 'BridgeTowerTextConfig', 'BridgeTowerVisionConfig', 'BrosConfig', 'BrosForTokenClassification', 'BrosModel', 'BrosPreTrainedModel', 'BrosProcessor', 'BrosSpadeEEForTokenClassification', 'BrosSpadeELForTokenClassification', 'ByT5Tokenizer', 'CAMEMBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CAMEMBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'CANINE_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CANINE_PRETRAINED_MODEL_ARCHIVE_LIST', 'CHINESE_CLIP_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CHINESE_CLIP_PRETRAINED_MODEL_ARCHIVE_LIST', 'CLAP_PRETRAINED_MODEL_ARCHIVE_LIST', 'CLIPConfig', 'CLIPFeatureExtractor', 'CLIPForImageClassification', 'CLIPImageProcessor', 'CLIPModel', 'CLIPPreTrainedModel', 'CLIPProcessor', 'CLIPSEG_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CLIPSEG_PRETRAINED_MODEL_ARCHIVE_LIST', 'CLIPSegConfig', 'CLIPSegForImageSegmentation', 'CLIPSegModel', 'CLIPSegPreTrainedModel', 'CLIPSegProcessor', 'CLIPSegTextConfig', 'CLIPSegTextModel', 'CLIPSegVisionConfig', 'CLIPSegVisionModel', 'CLIPTextConfig', 'CLIPTextModel', 'CLIPTextModelWithProjection', 'CLIPTokenizer', 'CLIPTokenizerFast', 'CLIPVisionConfig', 'CLIPVisionModel', 'CLIPVisionModelWithProjection', 'CLIP_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CLIP_PRETRAINED_MODEL_ARCHIVE_LIST', 'CLVP_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CLVP_PRETRAINED_MODEL_ARCHIVE_LIST', 'CODEGEN_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CODEGEN_PRETRAINED_MODEL_ARCHIVE_LIST', 'CONDITIONAL_DETR_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CONDITIONAL_DETR_PRETRAINED_MODEL_ARCHIVE_LIST', 'CONFIG_MAPPING', 'CONFIG_NAME', 'CONVBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CONVBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'CONVNEXTV2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CONVNEXTV2_PRETRAINED_MODEL_ARCHIVE_LIST', 'CONVNEXT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CONVNEXT_PRETRAINED_MODEL_ARCHIVE_LIST', 'CPMANT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CPMANT_PRETRAINED_MODEL_ARCHIVE_LIST', 'CTRLConfig', 'CTRLForSequenceClassification', 'CTRLLMHeadModel', 'CTRLModel', 'CTRLPreTrainedModel', 'CTRLTokenizer', 'CTRL_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CTRL_PRETRAINED_MODEL_ARCHIVE_LIST', 'CVT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CVT_PRETRAINED_MODEL_ARCHIVE_LIST', 'Cache', 'CamembertConfig', 'CamembertForCausalLM', 'CamembertForMaskedLM', 'CamembertForMultipleChoice', 'CamembertForQuestionAnswering', 'CamembertForSequenceClassification', 'CamembertForTokenClassification', 'CamembertModel', 'CamembertPreTrainedModel', 'CamembertTokenizer', 'CamembertTokenizerFast', 'CanineConfig', 'CanineForMultipleChoice', 'CanineForQuestionAnswering', 'CanineForSequenceClassification', 'CanineForTokenClassification', 'CanineLayer', 'CanineModel', 'CaninePreTrainedModel', 'CanineTokenizer', 'CharSpan', 'CharacterTokenizer', 'ChineseCLIPConfig', 'ChineseCLIPFeatureExtractor', 'ChineseCLIPImageProcessor', 'ChineseCLIPModel', 'ChineseCLIPPreTrainedModel', 'ChineseCLIPProcessor', 'ChineseCLIPTextConfig', 'ChineseCLIPTextModel', 'ChineseCLIPVisionConfig', 'ChineseCLIPVisionModel', 'ClapAudioConfig', 'ClapAudioModel', 'ClapAudioModelWithProjection', 'ClapConfig', 'ClapFeatureExtractor', 'ClapModel', 'ClapPreTrainedModel', 'ClapProcessor', 'ClapTextConfig', 'ClapTextModel', 'ClapTextModelWithProjection', 'ClassifierFreeGuidanceLogitsProcessor', 'ClvpConfig', 'ClvpDecoder', 'ClvpDecoderConfig', 'ClvpEncoder', 'ClvpEncoderConfig', 'ClvpFeatureExtractor', 'ClvpForCausalLM', 'ClvpModel', 'ClvpModelForConditionalGeneration', 'ClvpPreTrainedModel', 'ClvpProcessor', 'ClvpTokenizer', 'CodeGenConfig', 'CodeGenForCausalLM', 'CodeGenModel', 'CodeGenPreTrainedModel', 'CodeGenTokenizer', 'CodeGenTokenizerFast', 'CodeLlamaTokenizer', 'CodeLlamaTokenizerFast', 'ConditionalDetrConfig', 'ConditionalDetrFeatureExtractor', 'ConditionalDetrForObjectDetection', 'ConditionalDetrForSegmentation', 'ConditionalDetrImageProcessor', 'ConditionalDetrModel', 'ConditionalDetrPreTrainedModel', 'ConstrainedBeamSearchScorer', 'Constraint', 'ConstraintListState', 'Conv1D', 'ConvBertConfig', 'ConvBertForMaskedLM', 'ConvBertForMultipleChoice', 'ConvBertForQuestionAnswering', 'ConvBertForSequenceClassification', 'ConvBertForTokenClassification', 'ConvBertLayer', 'ConvBertModel', 'ConvBertPreTrainedModel', 'ConvBertTokenizer', 'ConvBertTokenizerFast', 'ConvNextBackbone', 'ConvNextConfig', 'ConvNextFeatureExtractor', 'ConvNextForImageClassification', 'ConvNextImageProcessor', 'ConvNextModel', 'ConvNextPreTrainedModel', 'ConvNextV2Backbone', 'ConvNextV2Config', 'ConvNextV2ForImageClassification', 'ConvNextV2Model', 'ConvNextV2PreTrainedModel', 'Conversation', 'ConversationalPipeline', 'CpmAntConfig', 'CpmAntForCausalLM', 'CpmAntModel', 'CpmAntPreTrainedModel', 'CpmAntTokenizer', 'CpmTokenizer', 'CpmTokenizerFast', 'CsvPipelineDataFormat', 'CvtConfig', 'CvtForImageClassification', 'CvtModel', 'CvtPreTrainedModel', 'DATA2VEC_AUDIO_PRETRAINED_MODEL_ARCHIVE_LIST', 'DATA2VEC_TEXT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DATA2VEC_TEXT_PRETRAINED_MODEL_ARCHIVE_LIST', 'DATA2VEC_VISION_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DATA2VEC_VISION_PRETRAINED_MODEL_ARCHIVE_LIST', 'DEBERTA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DEBERTA_PRETRAINED_MODEL_ARCHIVE_LIST', 'DEBERTA_V2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DEBERTA_V2_PRETRAINED_MODEL_ARCHIVE_LIST', 'DECISION_TRANSFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DECISION_TRANSFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'DEFORMABLE_DETR_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DEFORMABLE_DETR_PRETRAINED_MODEL_ARCHIVE_LIST', 'DEIT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DEIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'DEPTH_ANYTHING_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DEPTH_ANYTHING_PRETRAINED_MODEL_ARCHIVE_LIST', 'DETA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DETA_PRETRAINED_MODEL_ARCHIVE_LIST', 'DETR_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DETR_PRETRAINED_MODEL_ARCHIVE_LIST', 'DINAT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DINAT_PRETRAINED_MODEL_ARCHIVE_LIST', 'DINOV2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DINOV2_PRETRAINED_MODEL_ARCHIVE_LIST', 'DISTILBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DISTILBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'DONUT_SWIN_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DONUT_SWIN_PRETRAINED_MODEL_ARCHIVE_LIST', 'DPRConfig', 'DPRContextEncoder', 'DPRContextEncoderTokenizer', 'DPRContextEncoderTokenizerFast', 'DPRPreTrainedModel', 'DPRPretrainedContextEncoder', 'DPRPretrainedQuestionEncoder', 'DPRPretrainedReader', 'DPRQuestionEncoder', 'DPRQuestionEncoderTokenizer', 'DPRQuestionEncoderTokenizerFast', 'DPRReader', 'DPRReaderOutput', 'DPRReaderTokenizer', 'DPRReaderTokenizerFast', 'DPR_CONTEXT_ENCODER_PRETRAINED_MODEL_ARCHIVE_LIST', 'DPR_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DPR_QUESTION_ENCODER_PRETRAINED_MODEL_ARCHIVE_LIST', 'DPR_READER_PRETRAINED_MODEL_ARCHIVE_LIST', 'DPTConfig', 'DPTFeatureExtractor', 'DPTForDepthEstimation', 'DPTForSemanticSegmentation', 'DPTImageProcessor', 'DPTModel', 'DPTPreTrainedModel', 'DPT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DPT_PRETRAINED_MODEL_ARCHIVE_LIST', 'Data2VecAudioConfig', 'Data2VecAudioForAudioFrameClassification', 'Data2VecAudioForCTC', 'Data2VecAudioForSequenceClassification', 'Data2VecAudioForXVector', 'Data2VecAudioModel', 'Data2VecAudioPreTrainedModel', 'Data2VecTextConfig', 'Data2VecTextForCausalLM', 'Data2VecTextForMaskedLM', 'Data2VecTextForMultipleChoice', 'Data2VecTextForQuestionAnswering', 'Data2VecTextForSequenceClassification', 'Data2VecTextForTokenClassification', 'Data2VecTextModel', 'Data2VecTextPreTrainedModel', 'Data2VecVisionConfig', 'Data2VecVisionForImageClassification', 'Data2VecVisionForSemanticSegmentation', 'Data2VecVisionModel', 'Data2VecVisionPreTrainedModel', 'DataCollator', 'DataCollatorForLanguageModeling', 'DataCollatorForPermutationLanguageModeling', 'DataCollatorForSOP', 'DataCollatorForSeq2Seq', 'DataCollatorForTokenClassification', 'DataCollatorForWholeWordMask', 'DataCollatorWithPadding', 'DataProcessor', 'DebertaConfig', 'DebertaForMaskedLM', 'DebertaForQuestionAnswering', 'DebertaForSequenceClassification', 'DebertaForTokenClassification', 'DebertaModel', 'DebertaPreTrainedModel', 'DebertaTokenizer', 'DebertaTokenizerFast', 'DebertaV2Config', 'DebertaV2ForMaskedLM', 'DebertaV2ForMultipleChoice', 'DebertaV2ForQuestionAnswering', 'DebertaV2ForSequenceClassification', 'DebertaV2ForTokenClassification', 'DebertaV2Model', 'DebertaV2PreTrainedModel', 'DebertaV2Tokenizer', 'DebertaV2TokenizerFast', 'DecisionTransformerConfig', 'DecisionTransformerGPT2Model', 'DecisionTransformerGPT2PreTrainedModel', 'DecisionTransformerModel', 'DecisionTransformerPreTrainedModel', 'DefaultDataCollator', 'DefaultFlowCallback', 'DeformableDetrConfig', 'DeformableDetrFeatureExtractor', 'DeformableDetrForObjectDetection', 'DeformableDetrImageProcessor', 'DeformableDetrModel', 'DeformableDetrPreTrainedModel', 'DeiTConfig', 'DeiTFeatureExtractor', 'DeiTForImageClassification', 'DeiTForImageClassificationWithTeacher', 'DeiTForMaskedImageModeling', 'DeiTImageProcessor', 'DeiTModel', 'DeiTPreTrainedModel', 'DepthAnythingConfig', 'DepthAnythingForDepthEstimation', 'DepthAnythingPreTrainedModel', 'DepthEstimationPipeline', 'DetaConfig', 'DetaForObjectDetection', 'DetaImageProcessor', 'DetaModel', 'DetaPreTrainedModel', 'DetrConfig', 'DetrFeatureExtractor', 'DetrForObjectDetection', 'DetrForSegmentation', 'DetrImageProcessor', 'DetrModel', 'DetrPreTrainedModel', 'DinatBackbone', 'DinatConfig', 'DinatForImageClassification', 'DinatModel', 'DinatPreTrainedModel', 'Dinov2Backbone', 'Dinov2Config', 'Dinov2ForImageClassification', 'Dinov2Model', 'Dinov2PreTrainedModel', 'DisjunctiveConstraint', 'DistilBertConfig', 'DistilBertForMaskedLM', 'DistilBertForMultipleChoice', 'DistilBertForQuestionAnswering', 'DistilBertForSequenceClassification', 'DistilBertForTokenClassification', 'DistilBertModel', 'DistilBertPreTrainedModel', 'DistilBertTokenizer', 'DistilBertTokenizerFast', 'DocumentQuestionAnsweringPipeline', 'DonutFeatureExtractor', 'DonutImageProcessor', 'DonutProcessor', 'DonutSwinConfig', 'DonutSwinModel', 'DonutSwinPreTrainedModel', 'DummyObject', 'DynamicCache', 'EFFICIENTFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'EFFICIENTFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'EFFICIENTNET_PRETRAINED_CONFIG_ARCHIVE_MAP', 'EFFICIENTNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'ELECTRA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ELECTRA_PRETRAINED_MODEL_ARCHIVE_LIST', 'ENCODEC_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ENCODEC_PRETRAINED_MODEL_ARCHIVE_LIST', 'ERNIE_M_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ERNIE_M_PRETRAINED_MODEL_ARCHIVE_LIST', 'ERNIE_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ERNIE_PRETRAINED_MODEL_ARCHIVE_LIST', 'ESM_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ESM_PRETRAINED_MODEL_ARCHIVE_LIST', 'EarlyStoppingCallback', 'EfficientFormerConfig', 'EfficientFormerForImageClassification', 'EfficientFormerForImageClassificationWithTeacher', 'EfficientFormerImageProcessor', 'EfficientFormerModel', 'EfficientFormerPreTrainedModel', 'EfficientNetConfig', 'EfficientNetForImageClassification', 'EfficientNetImageProcessor', 'EfficientNetModel', 'EfficientNetPreTrainedModel', 'ElectraConfig', 'ElectraForCausalLM', 'ElectraForMaskedLM', 'ElectraForMultipleChoice', 'ElectraForPreTraining', 'ElectraForQuestionAnswering', 'ElectraForSequenceClassification', 'ElectraForTokenClassification', 'ElectraModel', 'ElectraPreTrainedModel', 'ElectraTokenizer', 'ElectraTokenizerFast', 'EncodecConfig', 'EncodecFeatureExtractor', 'EncodecModel', 'EncodecPreTrainedModel', 'EncoderDecoderConfig', 'EncoderDecoderModel', 'EncoderNoRepeatNGramLogitsProcessor', 'EncoderRepetitionPenaltyLogitsProcessor', 'EpsilonLogitsWarper', 'ErnieConfig', 'ErnieForCausalLM', 'ErnieForMaskedLM', 'ErnieForMultipleChoice', 'ErnieForNextSentencePrediction', 'ErnieForPreTraining', 'ErnieForQuestionAnswering', 'ErnieForSequenceClassification', 'ErnieForTokenClassification', 'ErnieMConfig', 'ErnieMForInformationExtraction', 'ErnieMForMultipleChoice', 'ErnieMForQuestionAnswering', 'ErnieMForSequenceClassification', 'ErnieMForTokenClassification', 'ErnieMModel', 'ErnieMPreTrainedModel', 'ErnieMTokenizer', 'ErnieModel', 'ErniePreTrainedModel', 'EsmConfig', 'EsmFoldPreTrainedModel', 'EsmForMaskedLM', 'EsmForProteinFolding', 'EsmForSequenceClassification', 'EsmForTokenClassification', 'EsmModel', 'EsmPreTrainedModel', 'EsmTokenizer', 'EtaLogitsWarper', 'EvalPrediction', 'ExponentialDecayLengthPenalty', 'FALCON_PRETRAINED_CONFIG_ARCHIVE_MAP', 'FALCON_PRETRAINED_MODEL_ARCHIVE_LIST', 'FASTSPEECH2_CONFORMER_HIFIGAN_PRETRAINED_CONFIG_ARCHIVE_MAP', 'FASTSPEECH2_CONFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'FASTSPEECH2_CONFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'FASTSPEECH2_CONFORMER_WITH_HIFIGAN_PRETRAINED_CONFIG_ARCHIVE_MAP', 'FEATURE_EXTRACTOR_MAPPING', 'FLAUBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'FLAUBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'FLAVA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'FLAVA_PRETRAINED_MODEL_ARCHIVE_LIST', 'FLAX_MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING', 'FLAX_MODEL_FOR_CAUSAL_LM_MAPPING', 'FLAX_MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING', 'FLAX_MODEL_FOR_MASKED_LM_MAPPING', 'FLAX_MODEL_FOR_MULTIPLE_CHOICE_MAPPING', 'FLAX_MODEL_FOR_NEXT_SENTENCE_PREDICTION_MAPPING', 'FLAX_MODEL_FOR_PRETRAINING_MAPPING', 'FLAX_MODEL_FOR_QUESTION_ANSWERING_MAPPING', 'FLAX_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING', 'FLAX_MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING', 'FLAX_MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING', 'FLAX_MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING', 'FLAX_MODEL_FOR_VISION_2_SEQ_MAPPING', 'FLAX_MODEL_MAPPING', 'FLAX_XLM_ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST', 'FNET_PRETRAINED_CONFIG_ARCHIVE_MAP', 'FNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'FNetConfig', 'FNetForMaskedLM', 'FNetForMultipleChoice', 'FNetForNextSentencePrediction', 'FNetForPreTraining', 'FNetForQuestionAnswering', 'FNetForSequenceClassification', 'FNetForTokenClassification', 'FNetLayer', 'FNetModel', 'FNetPreTrainedModel', 'FNetTokenizer', 'FNetTokenizerFast', 'FOCALNET_PRETRAINED_CONFIG_ARCHIVE_MAP', 'FOCALNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'FSMTConfig', 'FSMTForConditionalGeneration', 'FSMTModel', 'FSMTTokenizer', 'FSMT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'FUNNEL_PRETRAINED_CONFIG_ARCHIVE_MAP', 'FUNNEL_PRETRAINED_MODEL_ARCHIVE_LIST', 'FUYU_PRETRAINED_CONFIG_ARCHIVE_MAP', 'FalconConfig', 'FalconForCausalLM', 'FalconForQuestionAnswering', 'FalconForSequenceClassification', 'FalconForTokenClassification', 'FalconModel', 'FalconPreTrainedModel', 'FastSpeech2ConformerConfig', 'FastSpeech2ConformerHifiGan', 'FastSpeech2ConformerHifiGanConfig', 'FastSpeech2ConformerModel', 'FastSpeech2ConformerPreTrainedModel', 'FastSpeech2ConformerTokenizer', 'FastSpeech2ConformerWithHifiGan', 'FastSpeech2ConformerWithHifiGanConfig', 'FeatureExtractionMixin', 'FeatureExtractionPipeline', 'FillMaskPipeline', 'FlaubertConfig', 'FlaubertForMultipleChoice', 'FlaubertForQuestionAnswering', 'FlaubertForQuestionAnsweringSimple', 'FlaubertForSequenceClassification', 'FlaubertForTokenClassification', 'FlaubertModel', 'FlaubertPreTrainedModel', 'FlaubertTokenizer', 'FlaubertWithLMHeadModel', 'FlavaConfig', 'FlavaFeatureExtractor', 'FlavaForPreTraining', 'FlavaImageCodebook', 'FlavaImageCodebookConfig', 'FlavaImageConfig', 'FlavaImageModel', 'FlavaImageProcessor', 'FlavaModel', 'FlavaMultimodalConfig', 'FlavaMultimodalModel', 'FlavaPreTrainedModel', 'FlavaProcessor', 'FlavaTextConfig', 'FlavaTextModel', 'FlaxAlbertForMaskedLM', 'FlaxAlbertForMultipleChoice', 'FlaxAlbertForPreTraining', 'FlaxAlbertForQuestionAnswering', 'FlaxAlbertForSequenceClassification', 'FlaxAlbertForTokenClassification', 'FlaxAlbertModel', 'FlaxAlbertPreTrainedModel', 'FlaxAutoModel', 'FlaxAutoModelForCausalLM', 'FlaxAutoModelForImageClassification', 'FlaxAutoModelForMaskedLM', 'FlaxAutoModelForMultipleChoice', 'FlaxAutoModelForNextSentencePrediction', 'FlaxAutoModelForPreTraining', 'FlaxAutoModelForQuestionAnswering', 'FlaxAutoModelForSeq2SeqLM', 'FlaxAutoModelForSequenceClassification', 'FlaxAutoModelForSpeechSeq2Seq', 'FlaxAutoModelForTokenClassification', 'FlaxAutoModelForVision2Seq', 'FlaxBartDecoderPreTrainedModel', 'FlaxBartForCausalLM', 'FlaxBartForConditionalGeneration', 'FlaxBartForQuestionAnswering', 'FlaxBartForSequenceClassification', 'FlaxBartModel', 'FlaxBartPreTrainedModel', 'FlaxBeitForImageClassification', 'FlaxBeitForMaskedImageModeling', 'FlaxBeitModel', 'FlaxBeitPreTrainedModel', 'FlaxBertForCausalLM', 'FlaxBertForMaskedLM', 'FlaxBertForMultipleChoice', 'FlaxBertForNextSentencePrediction', 'FlaxBertForPreTraining', 'FlaxBertForQuestionAnswering', 'FlaxBertForSequenceClassification', 'FlaxBertForTokenClassification', 'FlaxBertModel', 'FlaxBertPreTrainedModel', 'FlaxBigBirdForCausalLM', 'FlaxBigBirdForMaskedLM', 'FlaxBigBirdForMultipleChoice', 'FlaxBigBirdForPreTraining', 'FlaxBigBirdForQuestionAnswering', 'FlaxBigBirdForSequenceClassification', 'FlaxBigBirdForTokenClassification', 'FlaxBigBirdModel', 'FlaxBigBirdPreTrainedModel', 'FlaxBlenderbotForConditionalGeneration', 'FlaxBlenderbotModel', 'FlaxBlenderbotPreTrainedModel', 'FlaxBlenderbotSmallForConditionalGeneration', 'FlaxBlenderbotSmallModel', 'FlaxBlenderbotSmallPreTrainedModel', 'FlaxBloomForCausalLM', 'FlaxBloomModel', 'FlaxBloomPreTrainedModel', 'FlaxCLIPModel', 'FlaxCLIPPreTrainedModel', 'FlaxCLIPTextModel', 'FlaxCLIPTextModelWithProjection', 'FlaxCLIPTextPreTrainedModel', 'FlaxCLIPVisionModel', 'FlaxCLIPVisionPreTrainedModel', 'FlaxDistilBertForMaskedLM', 'FlaxDistilBertForMultipleChoice', 'FlaxDistilBertForQuestionAnswering', 'FlaxDistilBertForSequenceClassification', 'FlaxDistilBertForTokenClassification', 'FlaxDistilBertModel', 'FlaxDistilBertPreTrainedModel', 'FlaxElectraForCausalLM', 'FlaxElectraForMaskedLM', 'FlaxElectraForMultipleChoice', 'FlaxElectraForPreTraining', 'FlaxElectraForQuestionAnswering', 'FlaxElectraForSequenceClassification', 'FlaxElectraForTokenClassification', 'FlaxElectraModel', 'FlaxElectraPreTrainedModel', 'FlaxEncoderDecoderModel', 'FlaxForceTokensLogitsProcessor', 'FlaxForcedBOSTokenLogitsProcessor', 'FlaxForcedEOSTokenLogitsProcessor', 'FlaxGPT2LMHeadModel', 'FlaxGPT2Model', 'FlaxGPT2PreTrainedModel', 'FlaxGPTJForCausalLM', 'FlaxGPTJModel', 'FlaxGPTJPreTrainedModel', 'FlaxGPTNeoForCausalLM', 'FlaxGPTNeoModel', 'FlaxGPTNeoPreTrainedModel', 'FlaxGenerationMixin', 'FlaxLlamaForCausalLM', 'FlaxLlamaModel', 'FlaxLlamaPreTrainedModel', 'FlaxLogitsProcessor', 'FlaxLogitsProcessorList', 'FlaxLogitsWarper', 'FlaxLongT5ForConditionalGeneration', 'FlaxLongT5Model', 'FlaxLongT5PreTrainedModel', 'FlaxMBartForConditionalGeneration', 'FlaxMBartForQuestionAnswering', 'FlaxMBartForSequenceClassification', 'FlaxMBartModel', 'FlaxMBartPreTrainedModel', 'FlaxMT5EncoderModel', 'FlaxMT5ForConditionalGeneration', 'FlaxMT5Model', 'FlaxMarianMTModel', 'FlaxMarianModel', 'FlaxMarianPreTrainedModel', 'FlaxMinLengthLogitsProcessor', 'FlaxMistralForCausalLM', 'FlaxMistralModel', 'FlaxMistralPreTrainedModel', 'FlaxOPTForCausalLM', 'FlaxOPTModel', 'FlaxOPTPreTrainedModel', 'FlaxPegasusForConditionalGeneration', 'FlaxPegasusModel', 'FlaxPegasusPreTrainedModel', 'FlaxPreTrainedModel', 'FlaxRegNetForImageClassification', 'FlaxRegNetModel', 'FlaxRegNetPreTrainedModel', 'FlaxResNetForImageClassification', 'FlaxResNetModel', 'FlaxResNetPreTrainedModel', 'FlaxRoFormerForMaskedLM', 'FlaxRoFormerForMultipleChoice', 'FlaxRoFormerForQuestionAnswering', 'FlaxRoFormerForSequenceClassification', 'FlaxRoFormerForTokenClassification', 'FlaxRoFormerModel', 'FlaxRoFormerPreTrainedModel', 'FlaxRobertaForCausalLM', 'FlaxRobertaForMaskedLM', 'FlaxRobertaForMultipleChoice', 'FlaxRobertaForQuestionAnswering', 'FlaxRobertaForSequenceClassification', 'FlaxRobertaForTokenClassification', 'FlaxRobertaModel', 'FlaxRobertaPreLayerNormForCausalLM', 'FlaxRobertaPreLayerNormForMaskedLM', 'FlaxRobertaPreLayerNormForMultipleChoice', 'FlaxRobertaPreLayerNormForQuestionAnswering', 'FlaxRobertaPreLayerNormForSequenceClassification', 'FlaxRobertaPreLayerNormForTokenClassification', 'FlaxRobertaPreLayerNormModel', 'FlaxRobertaPreLayerNormPreTrainedModel', 'FlaxRobertaPreTrainedModel', 'FlaxSpeechEncoderDecoderModel', 'FlaxSuppressTokensAtBeginLogitsProcessor', 'FlaxSuppressTokensLogitsProcessor', 'FlaxT5EncoderModel', 'FlaxT5ForConditionalGeneration', 'FlaxT5Model', 'FlaxT5PreTrainedModel', 'FlaxTemperatureLogitsWarper', 'FlaxTopKLogitsWarper', 'FlaxTopPLogitsWarper', 'FlaxViTForImageClassification', 'FlaxViTModel', 'FlaxViTPreTrainedModel', 'FlaxVisionEncoderDecoderModel', 'FlaxVisionTextDualEncoderModel', 'FlaxWav2Vec2ForCTC', 'FlaxWav2Vec2ForPreTraining', 'FlaxWav2Vec2Model', 'FlaxWav2Vec2PreTrainedModel', 'FlaxWhisperForAudioClassification', 'FlaxWhisperForConditionalGeneration', 'FlaxWhisperModel', 'FlaxWhisperPreTrainedModel', 'FlaxWhisperTimeStampLogitsProcessor', 'FlaxXGLMForCausalLM', 'FlaxXGLMModel', 'FlaxXGLMPreTrainedModel', 'FlaxXLMRobertaForCausalLM', 'FlaxXLMRobertaForMaskedLM', 'FlaxXLMRobertaForMultipleChoice', 'FlaxXLMRobertaForQuestionAnswering', 'FlaxXLMRobertaForSequenceClassification', 'FlaxXLMRobertaForTokenClassification', 'FlaxXLMRobertaModel', 'FlaxXLMRobertaPreTrainedModel', 'FocalNetBackbone', 'FocalNetConfig', 'FocalNetForImageClassification', 'FocalNetForMaskedImageModeling', 'FocalNetModel', 'FocalNetPreTrainedModel', 'ForceTokensLogitsProcessor', 'ForcedBOSTokenLogitsProcessor', 'ForcedEOSTokenLogitsProcessor', 'FunnelBaseModel', 'FunnelConfig', 'FunnelForMaskedLM', 'FunnelForMultipleChoice', 'FunnelForPreTraining', 'FunnelForQuestionAnswering', 'FunnelForSequenceClassification', 'FunnelForTokenClassification', 'FunnelModel', 'FunnelPreTrainedModel', 'FunnelTokenizer', 'FunnelTokenizerFast', 'FuyuConfig', 'FuyuForCausalLM', 'FuyuImageProcessor', 'FuyuPreTrainedModel', 'FuyuProcessor', 'GIT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'GLPNConfig', 'GLPNFeatureExtractor', 'GLPNForDepthEstimation', 'GLPNImageProcessor', 'GLPNModel', 'GLPNPreTrainedModel', 'GLPN_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GLPN_PRETRAINED_MODEL_ARCHIVE_LIST', 'GPT2Config', 'GPT2DoubleHeadsModel', 'GPT2ForQuestionAnswering', 'GPT2ForSequenceClassification', 'GPT2ForTokenClassification', 'GPT2LMHeadModel', 'GPT2Model', 'GPT2PreTrainedModel', 'GPT2Tokenizer', 'GPT2TokenizerFast', 'GPT2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GPT2_PRETRAINED_MODEL_ARCHIVE_LIST', 'GPTBigCodeConfig', 'GPTBigCodeForCausalLM', 'GPTBigCodeForSequenceClassification', 'GPTBigCodeForTokenClassification', 'GPTBigCodeModel', 'GPTBigCodePreTrainedModel', 'GPTJConfig', 'GPTJForCausalLM', 'GPTJForQuestionAnswering', 'GPTJForSequenceClassification', 'GPTJModel', 'GPTJPreTrainedModel', 'GPTJ_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GPTJ_PRETRAINED_MODEL_ARCHIVE_LIST', 'GPTNeoConfig', 'GPTNeoForCausalLM', 'GPTNeoForQuestionAnswering', 'GPTNeoForSequenceClassification', 'GPTNeoForTokenClassification', 'GPTNeoModel', 'GPTNeoPreTrainedModel', 'GPTNeoXConfig', 'GPTNeoXForCausalLM', 'GPTNeoXForQuestionAnswering', 'GPTNeoXForSequenceClassification', 'GPTNeoXForTokenClassification', 'GPTNeoXJapaneseConfig', 'GPTNeoXJapaneseForCausalLM', 'GPTNeoXJapaneseLayer', 'GPTNeoXJapaneseModel', 'GPTNeoXJapanesePreTrainedModel', 'GPTNeoXJapaneseTokenizer', 'GPTNeoXLayer', 'GPTNeoXModel', 'GPTNeoXPreTrainedModel', 'GPTNeoXTokenizerFast', 'GPTQConfig', 'GPTSAN_JAPANESE_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GPTSAN_JAPANESE_PRETRAINED_MODEL_ARCHIVE_LIST', 'GPTSanJapaneseConfig', 'GPTSanJapaneseForConditionalGeneration', 'GPTSanJapaneseModel', 'GPTSanJapanesePreTrainedModel', 'GPTSanJapaneseTokenizer', 'GPTSw3Tokenizer', 'GPT_BIGCODE_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GPT_BIGCODE_PRETRAINED_MODEL_ARCHIVE_LIST', 'GPT_NEOX_JAPANESE_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GPT_NEOX_JAPANESE_PRETRAINED_MODEL_ARCHIVE_LIST', 'GPT_NEOX_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GPT_NEOX_PRETRAINED_MODEL_ARCHIVE_LIST', 'GPT_NEO_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GPT_NEO_PRETRAINED_MODEL_ARCHIVE_LIST', 'GRAPHORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GRAPHORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'GROUPVIT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GROUPVIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'GenerationConfig', 'GenerationMixin', 'GitConfig', 'GitForCausalLM', 'GitModel', 'GitPreTrainedModel', 'GitProcessor', 'GitVisionConfig', 'GitVisionModel', 'GlueDataTrainingArguments', 'GlueDataset', 'GradientAccumulator', 'GraphormerConfig', 'GraphormerForGraphClassification', 'GraphormerModel', 'GraphormerPreTrainedModel', 'GroupViTConfig', 'GroupViTModel', 'GroupViTPreTrainedModel', 'GroupViTTextConfig', 'GroupViTTextModel', 'GroupViTVisionConfig', 'GroupViTVisionModel', 'HUBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'HUBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'HammingDiversityLogitsProcessor', 'HerbertTokenizer', 'HerbertTokenizerFast', 'HfAgent', 'HfArgumentParser', 'HubertConfig', 'HubertForCTC', 'HubertForSequenceClassification', 'HubertModel', 'HubertPreTrainedModel', 'IBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'IBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'IBertConfig', 'IBertForMaskedLM', 'IBertForMultipleChoice', 'IBertForQuestionAnswering', 'IBertForSequenceClassification', 'IBertForTokenClassification', 'IBertModel', 'IBertPreTrainedModel', 'IDEFICS_PRETRAINED_CONFIG_ARCHIVE_MAP', 'IDEFICS_PRETRAINED_MODEL_ARCHIVE_LIST', 'IMAGEGPT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'IMAGEGPT_PRETRAINED_MODEL_ARCHIVE_LIST', 'IMAGE_PROCESSOR_MAPPING', 'INFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'INFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'INSTRUCTBLIP_PRETRAINED_CONFIG_ARCHIVE_MAP', 'INSTRUCTBLIP_PRETRAINED_MODEL_ARCHIVE_LIST', 'IdeficsConfig', 'IdeficsForVisionText2Text', 'IdeficsImageProcessor', 'IdeficsModel', 'IdeficsPreTrainedModel', 'IdeficsProcessor', 'ImageClassificationPipeline', 'ImageFeatureExtractionMixin', 'ImageFeatureExtractionPipeline', 'ImageGPTConfig', 'ImageGPTFeatureExtractor', 'ImageGPTForCausalImageModeling', 'ImageGPTForImageClassification', 'ImageGPTImageProcessor', 'ImageGPTModel', 'ImageGPTPreTrainedModel', 'ImageProcessingMixin', 'ImageSegmentationPipeline', 'ImageToImagePipeline', 'ImageToTextPipeline', 'InfNanRemoveLogitsProcessor', 'InformerConfig', 'InformerForPrediction', 'InformerModel', 'InformerPreTrainedModel', 'InputExample', 'InputFeatures', 'InstructBlipConfig', 'InstructBlipForConditionalGeneration', 'InstructBlipPreTrainedModel', 'InstructBlipProcessor', 'InstructBlipQFormerConfig', 'InstructBlipQFormerModel', 'InstructBlipVisionConfig', 'InstructBlipVisionModel', 'IntervalStrategy', 'JUKEBOX_PRETRAINED_CONFIG_ARCHIVE_MAP', 'JUKEBOX_PRETRAINED_MODEL_ARCHIVE_LIST', 'JsonPipelineDataFormat', 'JukeboxConfig', 'JukeboxModel', 'JukeboxPreTrainedModel', 'JukeboxPrior', 'JukeboxPriorConfig', 'JukeboxTokenizer', 'JukeboxVQVAE', 'JukeboxVQVAEConfig', 'KOSMOS2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'KOSMOS2_PRETRAINED_MODEL_ARCHIVE_LIST', 'KerasMetricCallback', 'Kosmos2Config', 'Kosmos2ForConditionalGeneration', 'Kosmos2Model', 'Kosmos2PreTrainedModel', 'Kosmos2Processor', 'LAYOUTLMV2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LAYOUTLMV2_PRETRAINED_MODEL_ARCHIVE_LIST', 'LAYOUTLMV3_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LAYOUTLMV3_PRETRAINED_MODEL_ARCHIVE_LIST', 'LAYOUTLM_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LAYOUTLM_PRETRAINED_MODEL_ARCHIVE_LIST', 'LEDConfig', 'LEDForConditionalGeneration', 'LEDForQuestionAnswering', 'LEDForSequenceClassification', 'LEDModel', 'LEDPreTrainedModel', 'LEDTokenizer', 'LEDTokenizerFast', 'LED_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LED_PRETRAINED_MODEL_ARCHIVE_LIST', 'LEVIT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LEVIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'LILT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LILT_PRETRAINED_MODEL_ARCHIVE_LIST', 'LLAMA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LLAVA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LLAVA_PRETRAINED_MODEL_ARCHIVE_LIST', 'LONGFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LONGFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'LONGT5_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LONGT5_PRETRAINED_MODEL_ARCHIVE_LIST', 'LUKE_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LUKE_PRETRAINED_MODEL_ARCHIVE_LIST', 'LXMERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LayoutLMConfig', 'LayoutLMForMaskedLM', 'LayoutLMForQuestionAnswering', 'LayoutLMForSequenceClassification', 'LayoutLMForTokenClassification', 'LayoutLMModel', 'LayoutLMPreTrainedModel', 'LayoutLMTokenizer', 'LayoutLMTokenizerFast', 'LayoutLMv2Config', 'LayoutLMv2FeatureExtractor', 'LayoutLMv2ForQuestionAnswering', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv2ForTokenClassification', 'LayoutLMv2ImageProcessor', 'LayoutLMv2Model', 'LayoutLMv2PreTrainedModel', 'LayoutLMv2Processor', 'LayoutLMv2Tokenizer', 'LayoutLMv2TokenizerFast', 'LayoutLMv3Config', 'LayoutLMv3FeatureExtractor', 'LayoutLMv3ForQuestionAnswering', 'LayoutLMv3ForSequenceClassification', 'LayoutLMv3ForTokenClassification', 'LayoutLMv3ImageProcessor', 'LayoutLMv3Model', 'LayoutLMv3PreTrainedModel', 'LayoutLMv3Processor', 'LayoutLMv3Tokenizer', 'LayoutLMv3TokenizerFast', 'LayoutXLMProcessor', 'LayoutXLMTokenizer', 'LayoutXLMTokenizerFast', 'LevitConfig', 'LevitFeatureExtractor', 'LevitForImageClassification', 'LevitForImageClassificationWithTeacher', 'LevitImageProcessor', 'LevitModel', 'LevitPreTrainedModel', 'LiltConfig', 'LiltForQuestionAnswering', 'LiltForSequenceClassification', 'LiltForTokenClassification', 'LiltModel', 'LiltPreTrainedModel', 'LineByLineTextDataset', 'LineByLineWithRefDataset', 'LineByLineWithSOPTextDataset', 'LlamaConfig', 'LlamaForCausalLM', 'LlamaForQuestionAnswering', 'LlamaForSequenceClassification', 'LlamaModel', 'LlamaPreTrainedModel', 'LlamaTokenizer', 'LlamaTokenizerFast', 'LlavaConfig', 'LlavaForConditionalGeneration', 'LlavaPreTrainedModel', 'LlavaProcessor', 'LocalAgent', 'LogitNormalization', 'LogitsProcessor', 'LogitsProcessorList', 'LogitsWarper', 'LongT5Config', 'LongT5EncoderModel', 'LongT5ForConditionalGeneration', 'LongT5Model', 'LongT5PreTrainedModel', 'LongformerConfig', 'LongformerForMaskedLM', 'LongformerForMultipleChoice', 'LongformerForQuestionAnswering', 'LongformerForSequenceClassification', 'LongformerForTokenClassification', 'LongformerModel', 'LongformerPreTrainedModel', 'LongformerSelfAttention', 'LongformerTokenizer', 'LongformerTokenizerFast', 'LukeConfig', 'LukeForEntityClassification', 'LukeForEntityPairClassification', 'LukeForEntitySpanClassification', 'LukeForMaskedLM', 'LukeForMultipleChoice', 'LukeForQuestionAnswering', 'LukeForSequenceClassification', 'LukeForTokenClassification', 'LukeModel', 'LukePreTrainedModel', 'LukeTokenizer', 'LxmertConfig', 'LxmertEncoder', 'LxmertForPreTraining', 'LxmertForQuestionAnswering', 'LxmertModel', 'LxmertPreTrainedModel', 'LxmertTokenizer', 'LxmertTokenizerFast', 'LxmertVisualFeatureEncoder', 'LxmertXLayer', 'M2M100Config', 'M2M100ForConditionalGeneration', 'M2M100Model', 'M2M100PreTrainedModel', 'M2M100Tokenizer', 'M2M_100_PRETRAINED_CONFIG_ARCHIVE_MAP', 'M2M_100_PRETRAINED_MODEL_ARCHIVE_LIST', 'MARKUPLM_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MARKUPLM_PRETRAINED_MODEL_ARCHIVE_LIST', 'MASK2FORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MASK2FORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'MASKFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MASKFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'MBart50Tokenizer', 'MBart50TokenizerFast', 'MBartConfig', 'MBartForCausalLM', 'MBartForConditionalGeneration', 'MBartForQuestionAnswering', 'MBartForSequenceClassification', 'MBartModel', 'MBartPreTrainedModel', 'MBartTokenizer', 'MBartTokenizerFast', 'MCTCTConfig', 'MCTCTFeatureExtractor', 'MCTCTForCTC', 'MCTCTModel', 'MCTCTPreTrainedModel', 'MCTCTProcessor', 'MCTCT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MCTCT_PRETRAINED_MODEL_ARCHIVE_LIST', 'MEGATRON_BERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MEGATRON_BERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'MEGA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MEGA_PRETRAINED_MODEL_ARCHIVE_LIST', 'MGP_STR_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MGP_STR_PRETRAINED_MODEL_ARCHIVE_LIST', 'MISTRAL_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MIXTRAL_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MLukeTokenizer', 'MMBTConfig', 'MMBTForClassification', 'MMBTModel', 'MOBILEBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MOBILEBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'MOBILENET_V1_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MOBILENET_V1_PRETRAINED_MODEL_ARCHIVE_LIST', 'MOBILENET_V2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MOBILENET_V2_PRETRAINED_MODEL_ARCHIVE_LIST', 'MOBILEVITV2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MOBILEVITV2_PRETRAINED_MODEL_ARCHIVE_LIST', 'MOBILEVIT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MOBILEVIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'MODEL_CARD_NAME', 'MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING', 'MODEL_FOR_AUDIO_FRAME_CLASSIFICATION_MAPPING', 'MODEL_FOR_AUDIO_XVECTOR_MAPPING', 'MODEL_FOR_BACKBONE_MAPPING', 'MODEL_FOR_CAUSAL_IMAGE_MODELING_MAPPING', 'MODEL_FOR_CAUSAL_LM_MAPPING', 'MODEL_FOR_CTC_MAPPING', 'MODEL_FOR_DEPTH_ESTIMATION_MAPPING', 'MODEL_FOR_DOCUMENT_QUESTION_ANSWERING_MAPPING', 'MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING', 'MODEL_FOR_IMAGE_SEGMENTATION_MAPPING', 'MODEL_FOR_IMAGE_TO_IMAGE_MAPPING', 'MODEL_FOR_INSTANCE_SEGMENTATION_MAPPING', 'MODEL_FOR_MASKED_IMAGE_MODELING_MAPPING', 'MODEL_FOR_MASKED_LM_MAPPING', 'MODEL_FOR_MASK_GENERATION_MAPPING', 'MODEL_FOR_MULTIPLE_CHOICE_MAPPING', 'MODEL_FOR_NEXT_SENTENCE_PREDICTION_MAPPING', 'MODEL_FOR_OBJECT_DETECTION_MAPPING', 'MODEL_FOR_PRETRAINING_MAPPING', 'MODEL_FOR_QUESTION_ANSWERING_MAPPING', 'MODEL_FOR_SEMANTIC_SEGMENTATION_MAPPING', 'MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING', 'MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING', 'MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING', 'MODEL_FOR_TABLE_QUESTION_ANSWERING_MAPPING', 'MODEL_FOR_TEXT_ENCODING_MAPPING', 'MODEL_FOR_TEXT_TO_SPECTROGRAM_MAPPING', 'MODEL_FOR_TEXT_TO_WAVEFORM_MAPPING', 'MODEL_FOR_TIME_SERIES_CLASSIFICATION_MAPPING', 'MODEL_FOR_TIME_SERIES_REGRESSION_MAPPING', 'MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING', 'MODEL_FOR_UNIVERSAL_SEGMENTATION_MAPPING', 'MODEL_FOR_VIDEO_CLASSIFICATION_MAPPING', 'MODEL_FOR_VISION_2_SEQ_MAPPING', 'MODEL_FOR_VISUAL_QUESTION_ANSWERING_MAPPING', 'MODEL_FOR_ZERO_SHOT_IMAGE_CLASSIFICATION_MAPPING', 'MODEL_FOR_ZERO_SHOT_OBJECT_DETECTION_MAPPING', 'MODEL_MAPPING', 'MODEL_NAMES_MAPPING', 'MODEL_WITH_LM_HEAD_MAPPING', 'MPNET_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MPNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'MPNetConfig', 'MPNetForMaskedLM', 'MPNetForMultipleChoice', 'MPNetForQuestionAnswering', 'MPNetForSequenceClassification', 'MPNetForTokenClassification', 'MPNetLayer', 'MPNetModel', 'MPNetPreTrainedModel', 'MPNetTokenizer', 'MPNetTokenizerFast', 'MPT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MPT_PRETRAINED_MODEL_ARCHIVE_LIST', 'MRA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MRA_PRETRAINED_MODEL_ARCHIVE_LIST', 'MT5Config', 'MT5EncoderModel', 'MT5ForConditionalGeneration', 'MT5ForQuestionAnswering', 'MT5ForSequenceClassification', 'MT5ForTokenClassification', 'MT5Model', 'MT5PreTrainedModel', 'MT5Tokenizer', 'MT5TokenizerFast', 'MUSICGEN_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MUSICGEN_PRETRAINED_MODEL_ARCHIVE_LIST', 'MVP_PRETRAINED_MODEL_ARCHIVE_LIST', 'MarianConfig', 'MarianForCausalLM', 'MarianMTModel', 'MarianModel', 'MarianTokenizer', 'MarkupLMConfig', 'MarkupLMFeatureExtractor', 'MarkupLMForQuestionAnswering', 'MarkupLMForSequenceClassification', 'MarkupLMForTokenClassification', 'MarkupLMModel', 'MarkupLMPreTrainedModel', 'MarkupLMProcessor', 'MarkupLMTokenizer', 'MarkupLMTokenizerFast', 'Mask2FormerConfig', 'Mask2FormerForUniversalSegmentation', 'Mask2FormerImageProcessor', 'Mask2FormerModel', 'Mask2FormerPreTrainedModel', 'MaskFormerConfig', 'MaskFormerFeatureExtractor', 'MaskFormerForInstanceSegmentation', 'MaskFormerImageProcessor', 'MaskFormerModel', 'MaskFormerPreTrainedModel', 'MaskFormerSwinBackbone', 'MaskFormerSwinConfig', 'MaskGenerationPipeline', 'MaxLengthCriteria', 'MaxTimeCriteria', 'MecabTokenizer', 'MegaConfig', 'MegaForCausalLM', 'MegaForMaskedLM', 'MegaForMultipleChoice', 'MegaForQuestionAnswering', 'MegaForSequenceClassification', 'MegaForTokenClassification', 'MegaModel', 'MegaPreTrainedModel', 'MegatronBertConfig', 'MegatronBertForCausalLM', 'MegatronBertForMaskedLM', 'MegatronBertForMultipleChoice', 'MegatronBertForNextSentencePrediction', 'MegatronBertForPreTraining', 'MegatronBertForQuestionAnswering', 'MegatronBertForSequenceClassification', 'MegatronBertForTokenClassification', 'MegatronBertModel', 'MegatronBertPreTrainedModel', 'MgpstrConfig', 'MgpstrForSceneTextRecognition', 'MgpstrModel', 'MgpstrPreTrainedModel', 'MgpstrProcessor', 'MgpstrTokenizer', 'MinLengthLogitsProcessor', 'MinNewTokensLengthLogitsProcessor', 'MistralConfig', 'MistralForCausalLM', 'MistralForSequenceClassification', 'MistralModel', 'MistralPreTrainedModel', 'MixtralConfig', 'MixtralForCausalLM', 'MixtralForSequenceClassification', 'MixtralModel', 'MixtralPreTrainedModel', 'MobileBertConfig', 'MobileBertForMaskedLM', 'MobileBertForMultipleChoice', 'MobileBertForNextSentencePrediction', 'MobileBertForPreTraining', 'MobileBertForQuestionAnswering', 'MobileBertForSequenceClassification', 'MobileBertForTokenClassification', 'MobileBertLayer', 'MobileBertModel', 'MobileBertPreTrainedModel', 'MobileBertTokenizer', 'MobileBertTokenizerFast', 'MobileNetV1Config', 'MobileNetV1FeatureExtractor', 'MobileNetV1ForImageClassification', 'MobileNetV1ImageProcessor', 'MobileNetV1Model', 'MobileNetV1PreTrainedModel', 'MobileNetV2Config', 'MobileNetV2FeatureExtractor', 'MobileNetV2ForImageClassification', 'MobileNetV2ForSemanticSegmentation', 'MobileNetV2ImageProcessor', 'MobileNetV2Model', 'MobileNetV2PreTrainedModel', 'MobileViTConfig', 'MobileViTFeatureExtractor', 'MobileViTForImageClassification', 'MobileViTForSemanticSegmentation', 'MobileViTImageProcessor', 'MobileViTModel', 'MobileViTPreTrainedModel', 'MobileViTV2Config', 'MobileViTV2ForImageClassification', 'MobileViTV2ForSemanticSegmentation', 'MobileViTV2Model', 'MobileViTV2PreTrainedModel', 'ModalEmbeddings', 'ModelCard', 'MptConfig', 'MptForCausalLM', 'MptForQuestionAnswering', 'MptForSequenceClassification', 'MptForTokenClassification', 'MptModel', 'MptPreTrainedModel', 'MraConfig', 'MraForMaskedLM', 'MraForMultipleChoice', 'MraForQuestionAnswering', 'MraForSequenceClassification', 'MraForTokenClassification', 'MraModel', 'MraPreTrainedModel', 'MusicgenConfig', 'MusicgenDecoderConfig', 'MusicgenForCausalLM', 'MusicgenForConditionalGeneration', 'MusicgenModel', 'MusicgenPreTrainedModel', 'MusicgenProcessor', 'MvpConfig', 'MvpForCausalLM', 'MvpForConditionalGeneration', 'MvpForQuestionAnswering', 'MvpForSequenceClassification', 'MvpModel', 'MvpPreTrainedModel', 'MvpTokenizer', 'MvpTokenizerFast', 'NAT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'NAT_PRETRAINED_MODEL_ARCHIVE_LIST', 'NEZHA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'NEZHA_PRETRAINED_MODEL_ARCHIVE_LIST', 'NLLB_MOE_PRETRAINED_CONFIG_ARCHIVE_MAP', 'NLLB_MOE_PRETRAINED_MODEL_ARCHIVE_LIST', 'NYSTROMFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'NYSTROMFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'NatBackbone', 'NatConfig', 'NatForImageClassification', 'NatModel', 'NatPreTrainedModel', 'NerPipeline', 'NezhaConfig', 'NezhaForMaskedLM', 'NezhaForMultipleChoice', 'NezhaForNextSentencePrediction', 'NezhaForPreTraining', 'NezhaForQuestionAnswering', 'NezhaForSequenceClassification', 'NezhaForTokenClassification', 'NezhaModel', 'NezhaPreTrainedModel', 'NllbMoeConfig', 'NllbMoeForConditionalGeneration', 'NllbMoeModel', 'NllbMoePreTrainedModel', 'NllbMoeSparseMLP', 'NllbMoeTop2Router', 'NllbTokenizer', 'NllbTokenizerFast', 'NoBadWordsLogitsProcessor', 'NoRepeatNGramLogitsProcessor', 'NougatImageProcessor', 'NougatProcessor', 'NougatTokenizerFast', 'NystromformerConfig', 'NystromformerForMaskedLM', 'NystromformerForMultipleChoice', 'NystromformerForQuestionAnswering', 'NystromformerForSequenceClassification', 'NystromformerForTokenClassification', 'NystromformerLayer', 'NystromformerModel', 'NystromformerPreTrainedModel', 'ONEFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ONEFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'OPENAI_GPT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'OPENAI_GPT_PRETRAINED_MODEL_ARCHIVE_LIST', 'OPEN_LLAMA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'OPTConfig', 'OPTForCausalLM', 'OPTForQuestionAnswering', 'OPTForSequenceClassification', 'OPTModel', 'OPTPreTrainedModel', 'OPT_PRETRAINED_MODEL_ARCHIVE_LIST', 'OWLV2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'OWLV2_PRETRAINED_MODEL_ARCHIVE_LIST', 'OWLVIT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'OWLVIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'ObjectDetectionPipeline', 'OneFormerConfig', 'OneFormerForUniversalSegmentation', 'OneFormerImageProcessor', 'OneFormerModel', 'OneFormerPreTrainedModel', 'OneFormerProcessor', 'OpenAIGPTConfig', 'OpenAIGPTDoubleHeadsModel', 'OpenAIGPTForSequenceClassification', 'OpenAIGPTLMHeadModel', 'OpenAIGPTModel', 'OpenAIGPTPreTrainedModel', 'OpenAIGPTTokenizer', 'OpenAIGPTTokenizerFast', 'OpenAiAgent', 'OpenLlamaConfig', 'OpenLlamaForCausalLM', 'OpenLlamaForSequenceClassification', 'OpenLlamaModel', 'OpenLlamaPreTrainedModel', 'OwlViTConfig', 'OwlViTFeatureExtractor', 'OwlViTForObjectDetection', 'OwlViTImageProcessor', 'OwlViTModel', 'OwlViTPreTrainedModel', 'OwlViTProcessor', 'OwlViTTextConfig', 'OwlViTTextModel', 'OwlViTVisionConfig', 'OwlViTVisionModel', 'Owlv2Config', 'Owlv2ForObjectDetection', 'Owlv2ImageProcessor', 'Owlv2Model', 'Owlv2PreTrainedModel', 'Owlv2Processor', 'Owlv2TextConfig', 'Owlv2TextModel', 'Owlv2VisionConfig', 'Owlv2VisionModel', 'PATCHTSMIXER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'PATCHTSMIXER_PRETRAINED_MODEL_ARCHIVE_LIST', 'PATCHTST_PRETRAINED_CONFIG_ARCHIVE_MAP', 'PATCHTST_PRETRAINED_MODEL_ARCHIVE_LIST', 'PEGASUS_PRETRAINED_CONFIG_ARCHIVE_MAP', 'PEGASUS_X_PRETRAINED_CONFIG_ARCHIVE_MAP', 'PEGASUS_X_PRETRAINED_MODEL_ARCHIVE_LIST', 'PERCEIVER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'PERCEIVER_PRETRAINED_MODEL_ARCHIVE_LIST', 'PERSIMMON_PRETRAINED_CONFIG_ARCHIVE_MAP', 'PHI_PRETRAINED_CONFIG_ARCHIVE_MAP', 'PHI_PRETRAINED_MODEL_ARCHIVE_LIST', 'PIX2STRUCT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'PIX2STRUCT_PRETRAINED_MODEL_ARCHIVE_LIST', 'PLBART_PRETRAINED_CONFIG_ARCHIVE_MAP', 'PLBART_PRETRAINED_MODEL_ARCHIVE_LIST', 'PLBartConfig', 'PLBartForCausalLM', 'PLBartForConditionalGeneration', 'PLBartForSequenceClassification', 'PLBartModel', 'PLBartPreTrainedModel', 'PLBartTokenizer', 'POOLFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'POOLFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'POP2PIANO_PRETRAINED_CONFIG_ARCHIVE_MAP', 'POP2PIANO_PRETRAINED_MODEL_ARCHIVE_LIST', 'PROCESSOR_MAPPING', 'PROPHETNET_PRETRAINED_CONFIG_ARCHIVE_MAP', 'PROPHETNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'PVT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'PVT_PRETRAINED_MODEL_ARCHIVE_LIST', 'PYTORCH_PRETRAINED_BERT_CACHE', 'PYTORCH_TRANSFORMERS_CACHE', 'PatchTSMixerConfig', 'PatchTSMixerForPrediction', 'PatchTSMixerForPretraining', 'PatchTSMixerForRegression', 'PatchTSMixerForTimeSeriesClassification', 'PatchTSMixerModel', 'PatchTSMixerPreTrainedModel', 'PatchTSTConfig', 'PatchTSTForClassification', 'PatchTSTForPrediction', 'PatchTSTForPretraining', 'PatchTSTForRegression', 'PatchTSTModel', 'PatchTSTPreTrainedModel', 'PegasusConfig', 'PegasusForCausalLM', 'PegasusForConditionalGeneration', 'PegasusModel', 'PegasusPreTrainedModel', 'PegasusTokenizer', 'PegasusTokenizerFast', 'PegasusXConfig', 'PegasusXForConditionalGeneration', 'PegasusXModel', 'PegasusXPreTrainedModel', 'PerceiverConfig', 'PerceiverFeatureExtractor', 'PerceiverForImageClassificationConvProcessing', 'PerceiverForImageClassificationFourier', 'PerceiverForImageClassificationLearned', 'PerceiverForMaskedLM', 'PerceiverForMultimodalAutoencoding', 'PerceiverForOpticalFlow', 'PerceiverForSequenceClassification', 'PerceiverImageProcessor', 'PerceiverLayer', 'PerceiverModel', 'PerceiverPreTrainedModel', 'PerceiverTokenizer', 'PersimmonConfig', 'PersimmonForCausalLM', 'PersimmonForSequenceClassification', 'PersimmonModel', 'PersimmonPreTrainedModel', 'PhiConfig', 'PhiForCausalLM', 'PhiForSequenceClassification', 'PhiForTokenClassification', 'PhiModel', 'PhiPreTrainedModel', 'PhobertTokenizer', 'PhrasalConstraint', 'PipedPipelineDataFormat', 'Pipeline', 'PipelineDataFormat', 'PipelineTool', 'Pix2StructConfig', 'Pix2StructForConditionalGeneration', 'Pix2StructImageProcessor', 'Pix2StructPreTrainedModel', 'Pix2StructProcessor', 'Pix2StructTextConfig', 'Pix2StructTextModel', 'Pix2StructVisionConfig', 'Pix2StructVisionModel', 'PoolFormerConfig', 'PoolFormerFeatureExtractor', 'PoolFormerForImageClassification', 'PoolFormerImageProcessor', 'PoolFormerModel', 'PoolFormerPreTrainedModel', 'Pop2PianoConfig', 'Pop2PianoFeatureExtractor', 'Pop2PianoForConditionalGeneration', 'Pop2PianoPreTrainedModel', 'Pop2PianoProcessor', 'Pop2PianoTokenizer', 'PreTrainedModel', 'PreTrainedTokenizer', 'PreTrainedTokenizerBase', 'PreTrainedTokenizerFast', 'PrefixConstrainedLogitsProcessor', 'PretrainedBartModel', 'PretrainedConfig', 'PretrainedFSMTModel', 'PrinterCallback', 'ProcessorMixin', 'ProgressCallback', 'ProphetNetConfig', 'ProphetNetDecoder', 'ProphetNetEncoder', 'ProphetNetForCausalLM', 'ProphetNetForConditionalGeneration', 'ProphetNetModel', 'ProphetNetPreTrainedModel', 'ProphetNetTokenizer', 'PushToHubCallback', 'PvtConfig', 'PvtForImageClassification', 'PvtImageProcessor', 'PvtModel', 'PvtPreTrainedModel', 'PyTorchBenchmark', 'PyTorchBenchmarkArguments', 'QDQBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'QDQBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'QDQBertConfig', 'QDQBertForMaskedLM', 'QDQBertForMultipleChoice', 'QDQBertForNextSentencePrediction', 'QDQBertForQuestionAnswering', 'QDQBertForSequenceClassification', 'QDQBertForTokenClassification', 'QDQBertLMHeadModel', 'QDQBertLayer', 'QDQBertModel', 'QDQBertPreTrainedModel', 'QWEN2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'QuestionAnsweringPipeline', 'Qwen2Config', 'Qwen2ForCausalLM', 'Qwen2ForSequenceClassification', 'Qwen2Model', 'Qwen2PreTrainedModel', 'Qwen2Tokenizer', 'Qwen2TokenizerFast', 'REALM_PRETRAINED_CONFIG_ARCHIVE_MAP', 'REALM_PRETRAINED_MODEL_ARCHIVE_LIST', 'REFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'REFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'REGNET_PRETRAINED_CONFIG_ARCHIVE_MAP', 'REGNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'REMBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'REMBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'RESNET_PRETRAINED_CONFIG_ARCHIVE_MAP', 'RESNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'RETRIBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'RETRIBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'ROBERTA_PRELAYERNORM_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ROBERTA_PRELAYERNORM_PRETRAINED_MODEL_ARCHIVE_LIST', 'ROBERTA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST', 'ROC_BERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ROC_BERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'ROFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ROFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'RWKV_PRETRAINED_CONFIG_ARCHIVE_MAP', 'RWKV_PRETRAINED_MODEL_ARCHIVE_LIST', 'RagConfig', 'RagModel', 'RagPreTrainedModel', 'RagRetriever', 'RagSequenceForGeneration', 'RagTokenForGeneration', 'RagTokenizer', 'RealmConfig', 'RealmEmbedder', 'RealmForOpenQA', 'RealmKnowledgeAugEncoder', 'RealmPreTrainedModel', 'RealmReader', 'RealmRetriever', 'RealmScorer', 'RealmTokenizer', 'RealmTokenizerFast', 'ReformerAttention', 'ReformerConfig', 'ReformerForMaskedLM', 'ReformerForQuestionAnswering', 'ReformerForSequenceClassification', 'ReformerLayer', 'ReformerModel', 'ReformerModelWithLMHead', 'ReformerPreTrainedModel', 'ReformerTokenizer', 'ReformerTokenizerFast', 'RegNetConfig', 'RegNetForImageClassification', 'RegNetModel', 'RegNetPreTrainedModel', 'RemBertConfig', 'RemBertForCausalLM', 'RemBertForMaskedLM', 'RemBertForMultipleChoice', 'RemBertForQuestionAnswering', 'RemBertForSequenceClassification', 'RemBertForTokenClassification', 'RemBertLayer', 'RemBertModel', 'RemBertPreTrainedModel', 'RemBertTokenizer', 'RemBertTokenizerFast', 'RemoteTool', 'RepetitionPenaltyLogitsProcessor', 'ResNetBackbone', 'ResNetConfig', 'ResNetForImageClassification', 'ResNetModel', 'ResNetPreTrainedModel', 'RetriBertConfig', 'RetriBertModel', 'RetriBertPreTrainedModel', 'RetriBertTokenizer', 'RetriBertTokenizerFast', 'RoCBertConfig', 'RoCBertForCausalLM', 'RoCBertForMaskedLM', 'RoCBertForMultipleChoice', 'RoCBertForPreTraining', 'RoCBertForQuestionAnswering', 'RoCBertForSequenceClassification', 'RoCBertForTokenClassification', 'RoCBertLayer', 'RoCBertModel', 'RoCBertPreTrainedModel', 'RoCBertTokenizer', 'RoFormerConfig', 'RoFormerForCausalLM', 'RoFormerForMaskedLM', 'RoFormerForMultipleChoice', 'RoFormerForQuestionAnswering', 'RoFormerForSequenceClassification', 'RoFormerForTokenClassification', 'RoFormerLayer', 'RoFormerModel', 'RoFormerPreTrainedModel', 'RoFormerTokenizer', 'RoFormerTokenizerFast', 'RobertaConfig', 'RobertaForCausalLM', 'RobertaForMaskedLM', 'RobertaForMultipleChoice', 'RobertaForQuestionAnswering', 'RobertaForSequenceClassification', 'RobertaForTokenClassification', 'RobertaModel', 'RobertaPreLayerNormConfig', 'RobertaPreLayerNormForCausalLM', 'RobertaPreLayerNormForMaskedLM', 'RobertaPreLayerNormForMultipleChoice', 'RobertaPreLayerNormForQuestionAnswering', 'RobertaPreLayerNormForSequenceClassification', 'RobertaPreLayerNormForTokenClassification', 'RobertaPreLayerNormModel', 'RobertaPreLayerNormPreTrainedModel', 'RobertaPreTrainedModel', 'RobertaTokenizer', 'RobertaTokenizerFast', 'RwkvConfig', 'RwkvForCausalLM', 'RwkvModel', 'RwkvPreTrainedModel', 'SAM_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SAM_PRETRAINED_MODEL_ARCHIVE_LIST', 'SEAMLESS_M4T_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SEAMLESS_M4T_PRETRAINED_MODEL_ARCHIVE_LIST', 'SEAMLESS_M4T_V2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SEAMLESS_M4T_V2_PRETRAINED_MODEL_ARCHIVE_LIST', 'SEGFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SEGFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'SEWConfig', 'SEWDConfig', 'SEWDForCTC', 'SEWDForSequenceClassification', 'SEWDModel', 'SEWDPreTrainedModel', 'SEWForCTC', 'SEWForSequenceClassification', 'SEWModel', 'SEWPreTrainedModel', 'SEW_D_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SEW_D_PRETRAINED_MODEL_ARCHIVE_LIST', 'SEW_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SEW_PRETRAINED_MODEL_ARCHIVE_LIST', 'SIGLIP_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SIGLIP_PRETRAINED_MODEL_ARCHIVE_LIST', 'SLOW_TO_FAST_CONVERTERS', 'SPEECHT5_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SPEECHT5_PRETRAINED_HIFIGAN_CONFIG_ARCHIVE_MAP', 'SPEECHT5_PRETRAINED_MODEL_ARCHIVE_LIST', 'SPEECH_TO_TEXT_2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SPEECH_TO_TEXT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SPEECH_TO_TEXT_PRETRAINED_MODEL_ARCHIVE_LIST', 'SPIECE_UNDERLINE', 'SPLINTER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SPLINTER_PRETRAINED_MODEL_ARCHIVE_LIST', 'SQUEEZEBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SQUEEZEBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'STABLELM_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SWIFTFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SWIFTFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'SWIN2SR_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SWIN2SR_PRETRAINED_MODEL_ARCHIVE_LIST', 'SWINV2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SWINV2_PRETRAINED_MODEL_ARCHIVE_LIST', 'SWIN_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SWIN_PRETRAINED_MODEL_ARCHIVE_LIST', 'SWITCH_TRANSFORMERS_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SWITCH_TRANSFORMERS_PRETRAINED_MODEL_ARCHIVE_LIST', 'SamConfig', 'SamImageProcessor', 'SamMaskDecoderConfig', 'SamModel', 'SamPreTrainedModel', 'SamProcessor', 'SamPromptEncoderConfig', 'SamVisionConfig', 'SchedulerType', 'SeamlessM4TCodeHifiGan', 'SeamlessM4TConfig', 'SeamlessM4TFeatureExtractor', 'SeamlessM4TForSpeechToSpeech', 'SeamlessM4TForSpeechToText', 'SeamlessM4TForTextToSpeech', 'SeamlessM4TForTextToText', 'SeamlessM4THifiGan', 'SeamlessM4TModel', 'SeamlessM4TPreTrainedModel', 'SeamlessM4TProcessor', 'SeamlessM4TTextToUnitForConditionalGeneration', 'SeamlessM4TTextToUnitModel', 'SeamlessM4TTokenizer', 'SeamlessM4TTokenizerFast', 'SeamlessM4Tv2Config', 'SeamlessM4Tv2ForSpeechToSpeech', 'SeamlessM4Tv2ForSpeechToText', 'SeamlessM4Tv2ForTextToSpeech', 'SeamlessM4Tv2ForTextToText', 'SeamlessM4Tv2Model', 'SeamlessM4Tv2PreTrainedModel', 'SegformerConfig', 'SegformerDecodeHead', 'SegformerFeatureExtractor', 'SegformerForImageClassification', 'SegformerForSemanticSegmentation', 'SegformerImageProcessor', 'SegformerLayer', 'SegformerModel', 'SegformerPreTrainedModel', 'Seq2SeqTrainer', 'Seq2SeqTrainingArguments', 'SequenceBiasLogitsProcessor', 'SequenceFeatureExtractor', 'SiglipConfig', 'SiglipForImageClassification', 'SiglipImageProcessor', 'SiglipModel', 'SiglipPreTrainedModel', 'SiglipProcessor', 'SiglipTextConfig', 'SiglipTextModel', 'SiglipTokenizer', 'SiglipVisionConfig', 'SiglipVisionModel', 'SingleSentenceClassificationProcessor', 'SinkCache', 'SpecialTokensMixin', 'Speech2Text2Config', 'Speech2Text2ForCausalLM', 'Speech2Text2PreTrainedModel', 'Speech2Text2Processor', 'Speech2Text2Tokenizer', 'Speech2TextConfig', 'Speech2TextFeatureExtractor', 'Speech2TextForConditionalGeneration', 'Speech2TextModel', 'Speech2TextPreTrainedModel', 'Speech2TextProcessor', 'Speech2TextTokenizer', 'SpeechEncoderDecoderConfig', 'SpeechEncoderDecoderModel', 'SpeechT5Config', 'SpeechT5FeatureExtractor', 'SpeechT5ForSpeechToSpeech', 'SpeechT5ForSpeechToText', 'SpeechT5ForTextToSpeech', 'SpeechT5HifiGan', 'SpeechT5HifiGanConfig', 'SpeechT5Model', 'SpeechT5PreTrainedModel', 'SpeechT5Processor', 'SpeechT5Tokenizer', 'SplinterConfig', 'SplinterForPreTraining', 'SplinterForQuestionAnswering', 'SplinterLayer', 'SplinterModel', 'SplinterPreTrainedModel', 'SplinterTokenizer', 'SplinterTokenizerFast', 'SquadDataTrainingArguments', 'SquadDataset', 'SquadExample', 'SquadFeatures', 'SquadV1Processor', 'SquadV2Processor', 'SqueezeBertConfig', 'SqueezeBertForMaskedLM', 'SqueezeBertForMultipleChoice', 'SqueezeBertForQuestionAnswering', 'SqueezeBertForSequenceClassification', 'SqueezeBertForTokenClassification', 'SqueezeBertModel', 'SqueezeBertModule', 'SqueezeBertPreTrainedModel', 'SqueezeBertTokenizer', 'SqueezeBertTokenizerFast', 'StableLmConfig', 'StableLmForCausalLM', 'StableLmForSequenceClassification', 'StableLmModel', 'StableLmPreTrainedModel', 'StaticCache', 'StoppingCriteria', 'StoppingCriteriaList', 'SummarizationPipeline', 'SuppressTokensAtBeginLogitsProcessor', 'SuppressTokensLogitsProcessor', 'SwiftFormerConfig', 'SwiftFormerForImageClassification', 'SwiftFormerModel', 'SwiftFormerPreTrainedModel', 'Swin2SRConfig', 'Swin2SRForImageSuperResolution', 'Swin2SRImageProcessor', 'Swin2SRModel', 'Swin2SRPreTrainedModel', 'SwinBackbone', 'SwinConfig', 'SwinForImageClassification', 'SwinForMaskedImageModeling', 'SwinModel', 'SwinPreTrainedModel', 'Swinv2Backbone', 'Swinv2Config', 'Swinv2ForImageClassification', 'Swinv2ForMaskedImageModeling', 'Swinv2Model', 'Swinv2PreTrainedModel', 'SwitchTransformersConfig', 'SwitchTransformersEncoderModel', 'SwitchTransformersForConditionalGeneration', 'SwitchTransformersModel', 'SwitchTransformersPreTrainedModel', 'SwitchTransformersSparseMLP', 'SwitchTransformersTop1Router', 'T5Config', 'T5EncoderModel', 'T5ForConditionalGeneration', 'T5ForQuestionAnswering', 'T5ForSequenceClassification', 'T5ForTokenClassification', 'T5Model', 'T5PreTrainedModel', 'T5Tokenizer', 'T5TokenizerFast', 'T5_PRETRAINED_CONFIG_ARCHIVE_MAP', 'T5_PRETRAINED_MODEL_ARCHIVE_LIST', 'TABLE_TRANSFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'TABLE_TRANSFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TAPAS_PRETRAINED_CONFIG_ARCHIVE_MAP', 'TAPAS_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF2_WEIGHTS_NAME', 'TFAdaptiveEmbedding', 'TFAlbertForMaskedLM', 'TFAlbertForMultipleChoice', 'TFAlbertForPreTraining', 'TFAlbertForQuestionAnswering', 'TFAlbertForSequenceClassification', 'TFAlbertForTokenClassification', 'TFAlbertMainLayer', 'TFAlbertModel', 'TFAlbertPreTrainedModel', 'TFAutoModel', 'TFAutoModelForAudioClassification', 'TFAutoModelForCausalLM', 'TFAutoModelForDocumentQuestionAnswering', 'TFAutoModelForImageClassification', 'TFAutoModelForMaskGeneration', 'TFAutoModelForMaskedImageModeling', 'TFAutoModelForMaskedLM', 'TFAutoModelForMultipleChoice', 'TFAutoModelForNextSentencePrediction', 'TFAutoModelForPreTraining', 'TFAutoModelForQuestionAnswering', 'TFAutoModelForSemanticSegmentation', 'TFAutoModelForSeq2SeqLM', 'TFAutoModelForSequenceClassification', 'TFAutoModelForSpeechSeq2Seq', 'TFAutoModelForTableQuestionAnswering', 'TFAutoModelForTextEncoding', 'TFAutoModelForTokenClassification', 'TFAutoModelForVision2Seq', 'TFAutoModelForZeroShotImageClassification', 'TFAutoModelWithLMHead', 'TFBartForConditionalGeneration', 'TFBartForSequenceClassification', 'TFBartModel', 'TFBartPretrainedModel', 'TFBertEmbeddings', 'TFBertForMaskedLM', 'TFBertForMultipleChoice', 'TFBertForNextSentencePrediction', 'TFBertForPreTraining', 'TFBertForQuestionAnswering', 'TFBertForSequenceClassification', 'TFBertForTokenClassification', 'TFBertLMHeadModel', 'TFBertMainLayer', 'TFBertModel', 'TFBertPreTrainedModel', 'TFBertTokenizer', 'TFBlenderbotForConditionalGeneration', 'TFBlenderbotModel', 'TFBlenderbotPreTrainedModel', 'TFBlenderbotSmallForConditionalGeneration', 'TFBlenderbotSmallModel', 'TFBlenderbotSmallPreTrainedModel', 'TFBlipForConditionalGeneration', 'TFBlipForImageTextRetrieval', 'TFBlipForQuestionAnswering', 'TFBlipModel', 'TFBlipPreTrainedModel', 'TFBlipTextModel', 'TFBlipVisionModel', 'TFCLIPModel', 'TFCLIPPreTrainedModel', 'TFCLIPTextModel', 'TFCLIPVisionModel', 'TFCTRLForSequenceClassification', 'TFCTRLLMHeadModel', 'TFCTRLModel', 'TFCTRLPreTrainedModel', 'TFCamembertForCausalLM', 'TFCamembertForMaskedLM', 'TFCamembertForMultipleChoice', 'TFCamembertForQuestionAnswering', 'TFCamembertForSequenceClassification', 'TFCamembertForTokenClassification', 'TFCamembertModel', 'TFCamembertPreTrainedModel', 'TFConvBertForMaskedLM', 'TFConvBertForMultipleChoice', 'TFConvBertForQuestionAnswering', 'TFConvBertForSequenceClassification', 'TFConvBertForTokenClassification', 'TFConvBertLayer', 'TFConvBertModel', 'TFConvBertPreTrainedModel', 'TFConvNextForImageClassification', 'TFConvNextModel', 'TFConvNextPreTrainedModel', 'TFConvNextV2ForImageClassification', 'TFConvNextV2Model', 'TFConvNextV2PreTrainedModel', 'TFCvtForImageClassification', 'TFCvtModel', 'TFCvtPreTrainedModel', 'TFDPRContextEncoder', 'TFDPRPretrainedContextEncoder', 'TFDPRPretrainedQuestionEncoder', 'TFDPRPretrainedReader', 'TFDPRQuestionEncoder', 'TFDPRReader', 'TFData2VecVisionForImageClassification', 'TFData2VecVisionForSemanticSegmentation', 'TFData2VecVisionModel', 'TFData2VecVisionPreTrainedModel', 'TFDebertaForMaskedLM', 'TFDebertaForQuestionAnswering', 'TFDebertaForSequenceClassification', 'TFDebertaForTokenClassification', 'TFDebertaModel', 'TFDebertaPreTrainedModel', 'TFDebertaV2ForMaskedLM', 'TFDebertaV2ForMultipleChoice', 'TFDebertaV2ForQuestionAnswering', 'TFDebertaV2ForSequenceClassification', 'TFDebertaV2ForTokenClassification', 'TFDebertaV2Model', 'TFDebertaV2PreTrainedModel', 'TFDeiTForImageClassification', 'TFDeiTForImageClassificationWithTeacher', 'TFDeiTForMaskedImageModeling', 'TFDeiTModel', 'TFDeiTPreTrainedModel', 'TFDistilBertForMaskedLM', 'TFDistilBertForMultipleChoice', 'TFDistilBertForQuestionAnswering', 'TFDistilBertForSequenceClassification', 'TFDistilBertForTokenClassification', 'TFDistilBertMainLayer', 'TFDistilBertModel', 'TFDistilBertPreTrainedModel', 'TFEfficientFormerForImageClassification', 'TFEfficientFormerForImageClassificationWithTeacher', 'TFEfficientFormerModel', 'TFEfficientFormerPreTrainedModel', 'TFElectraForMaskedLM', 'TFElectraForMultipleChoice', 'TFElectraForPreTraining', 'TFElectraForQuestionAnswering', 'TFElectraForSequenceClassification', 'TFElectraForTokenClassification', 'TFElectraModel', 'TFElectraPreTrainedModel', 'TFEncoderDecoderModel', 'TFEsmForMaskedLM', 'TFEsmForSequenceClassification', 'TFEsmForTokenClassification', 'TFEsmModel', 'TFEsmPreTrainedModel', 'TFFlaubertForMultipleChoice', 'TFFlaubertForQuestionAnsweringSimple', 'TFFlaubertForSequenceClassification', 'TFFlaubertForTokenClassification', 'TFFlaubertModel', 'TFFlaubertPreTrainedModel', 'TFFlaubertWithLMHeadModel', 'TFForceTokensLogitsProcessor', 'TFForcedBOSTokenLogitsProcessor', 'TFForcedEOSTokenLogitsProcessor', 'TFFunnelBaseModel', 'TFFunnelForMaskedLM', 'TFFunnelForMultipleChoice', 'TFFunnelForPreTraining', 'TFFunnelForQuestionAnswering', 'TFFunnelForSequenceClassification', 'TFFunnelForTokenClassification', 'TFFunnelModel', 'TFFunnelPreTrainedModel', 'TFGPT2DoubleHeadsModel', 'TFGPT2ForSequenceClassification', 'TFGPT2LMHeadModel', 'TFGPT2MainLayer', 'TFGPT2Model', 'TFGPT2PreTrainedModel', 'TFGPT2Tokenizer', 'TFGPTJForCausalLM', 'TFGPTJForQuestionAnswering', 'TFGPTJForSequenceClassification', 'TFGPTJModel', 'TFGPTJPreTrainedModel', 'TFGenerationMixin', 'TFGroupViTModel', 'TFGroupViTPreTrainedModel', 'TFGroupViTTextModel', 'TFGroupViTVisionModel', 'TFHubertForCTC', 'TFHubertModel', 'TFHubertPreTrainedModel', 'TFLEDForConditionalGeneration', 'TFLEDModel', 'TFLEDPreTrainedModel', 'TFLayoutLMForMaskedLM', 'TFLayoutLMForQuestionAnswering', 'TFLayoutLMForSequenceClassification', 'TFLayoutLMForTokenClassification', 'TFLayoutLMMainLayer', 'TFLayoutLMModel', 'TFLayoutLMPreTrainedModel', 'TFLayoutLMv3ForQuestionAnswering', 'TFLayoutLMv3ForSequenceClassification', 'TFLayoutLMv3ForTokenClassification', 'TFLayoutLMv3Model', 'TFLayoutLMv3PreTrainedModel', 'TFLogitsProcessor', 'TFLogitsProcessorList', 'TFLogitsWarper', 'TFLongformerForMaskedLM', 'TFLongformerForMultipleChoice', 'TFLongformerForQuestionAnswering', 'TFLongformerForSequenceClassification', 'TFLongformerForTokenClassification', 'TFLongformerModel', 'TFLongformerPreTrainedModel', 'TFLongformerSelfAttention', 'TFLxmertForPreTraining', 'TFLxmertMainLayer', 'TFLxmertModel', 'TFLxmertPreTrainedModel', 'TFLxmertVisualFeatureEncoder', 'TFMBartForConditionalGeneration', 'TFMBartModel', 'TFMBartPreTrainedModel', 'TFMPNetForMaskedLM', 'TFMPNetForMultipleChoice', 'TFMPNetForQuestionAnswering', 'TFMPNetForSequenceClassification', 'TFMPNetForTokenClassification', 'TFMPNetMainLayer', 'TFMPNetModel', 'TFMPNetPreTrainedModel', 'TFMT5EncoderModel', 'TFMT5ForConditionalGeneration', 'TFMT5Model', 'TFMarianMTModel', 'TFMarianModel', 'TFMarianPreTrainedModel', 'TFMinLengthLogitsProcessor', 'TFMobileBertForMaskedLM', 'TFMobileBertForMultipleChoice', 'TFMobileBertForNextSentencePrediction', 'TFMobileBertForPreTraining', 'TFMobileBertForQuestionAnswering', 'TFMobileBertForSequenceClassification', 'TFMobileBertForTokenClassification', 'TFMobileBertMainLayer', 'TFMobileBertModel', 'TFMobileBertPreTrainedModel', 'TFMobileViTForImageClassification', 'TFMobileViTForSemanticSegmentation', 'TFMobileViTModel', 'TFMobileViTPreTrainedModel', 'TFNoBadWordsLogitsProcessor', 'TFNoRepeatNGramLogitsProcessor', 'TFOPTForCausalLM', 'TFOPTModel', 'TFOPTPreTrainedModel', 'TFOpenAIGPTDoubleHeadsModel', 'TFOpenAIGPTForSequenceClassification', 'TFOpenAIGPTLMHeadModel', 'TFOpenAIGPTMainLayer', 'TFOpenAIGPTModel', 'TFOpenAIGPTPreTrainedModel', 'TFPegasusForConditionalGeneration', 'TFPegasusModel', 'TFPegasusPreTrainedModel', 'TFPreTrainedModel', 'TFRagModel', 'TFRagPreTrainedModel', 'TFRagSequenceForGeneration', 'TFRagTokenForGeneration', 'TFRegNetForImageClassification', 'TFRegNetModel', 'TFRegNetPreTrainedModel', 'TFRemBertForCausalLM', 'TFRemBertForMaskedLM', 'TFRemBertForMultipleChoice', 'TFRemBertForQuestionAnswering', 'TFRemBertForSequenceClassification', 'TFRemBertForTokenClassification', 'TFRemBertLayer', 'TFRemBertModel', 'TFRemBertPreTrainedModel', 'TFRepetitionPenaltyLogitsProcessor', 'TFResNetForImageClassification', 'TFResNetModel', 'TFResNetPreTrainedModel', 'TFRoFormerForCausalLM', 'TFRoFormerForMaskedLM', 'TFRoFormerForMultipleChoice', 'TFRoFormerForQuestionAnswering', 'TFRoFormerForSequenceClassification', 'TFRoFormerForTokenClassification', 'TFRoFormerLayer', 'TFRoFormerModel', 'TFRoFormerPreTrainedModel', 'TFRobertaForCausalLM', 'TFRobertaForMaskedLM', 'TFRobertaForMultipleChoice', 'TFRobertaForQuestionAnswering', 'TFRobertaForSequenceClassification', 'TFRobertaForTokenClassification', 'TFRobertaMainLayer', 'TFRobertaModel', 'TFRobertaPreLayerNormForCausalLM', 'TFRobertaPreLayerNormForMaskedLM', 'TFRobertaPreLayerNormForMultipleChoice', 'TFRobertaPreLayerNormForQuestionAnswering', 'TFRobertaPreLayerNormForSequenceClassification', 'TFRobertaPreLayerNormForTokenClassification', 'TFRobertaPreLayerNormMainLayer', 'TFRobertaPreLayerNormModel', 'TFRobertaPreLayerNormPreTrainedModel', 'TFRobertaPreTrainedModel', 'TFSamModel', 'TFSamPreTrainedModel', 'TFSegformerDecodeHead', 'TFSegformerForImageClassification', 'TFSegformerForSemanticSegmentation', 'TFSegformerModel', 'TFSegformerPreTrainedModel', 'TFSequenceSummary', 'TFSharedEmbeddings', 'TFSpeech2TextForConditionalGeneration', 'TFSpeech2TextModel', 'TFSpeech2TextPreTrainedModel', 'TFSuppressTokensAtBeginLogitsProcessor', 'TFSuppressTokensLogitsProcessor', 'TFSwinForImageClassification', 'TFSwinForMaskedImageModeling', 'TFSwinModel', 'TFSwinPreTrainedModel', 'TFT5EncoderModel', 'TFT5ForConditionalGeneration', 'TFT5Model', 'TFT5PreTrainedModel', 'TFTapasForMaskedLM', 'TFTapasForQuestionAnswering', 'TFTapasForSequenceClassification', 'TFTapasModel', 'TFTapasPreTrainedModel', 'TFTemperatureLogitsWarper', 'TFTopKLogitsWarper', 'TFTopPLogitsWarper', 'TFTrainingArguments', 'TFTransfoXLForSequenceClassification', 'TFTransfoXLLMHeadModel', 'TFTransfoXLMainLayer', 'TFTransfoXLModel', 'TFTransfoXLPreTrainedModel', 'TFViTForImageClassification', 'TFViTMAEForPreTraining', 'TFViTMAEModel', 'TFViTMAEPreTrainedModel', 'TFViTModel', 'TFViTPreTrainedModel', 'TFVisionEncoderDecoderModel', 'TFVisionTextDualEncoderModel', 'TFWav2Vec2ForCTC', 'TFWav2Vec2ForSequenceClassification', 'TFWav2Vec2Model', 'TFWav2Vec2PreTrainedModel', 'TFWhisperForConditionalGeneration', 'TFWhisperModel', 'TFWhisperPreTrainedModel', 'TFXGLMForCausalLM', 'TFXGLMModel', 'TFXGLMPreTrainedModel', 'TFXLMForMultipleChoice', 'TFXLMForQuestionAnsweringSimple', 'TFXLMForSequenceClassification', 'TFXLMForTokenClassification', 'TFXLMMainLayer', 'TFXLMModel', 'TFXLMPreTrainedModel', 'TFXLMRobertaForCausalLM', 'TFXLMRobertaForMaskedLM', 'TFXLMRobertaForMultipleChoice', 'TFXLMRobertaForQuestionAnswering', 'TFXLMRobertaForSequenceClassification', 'TFXLMRobertaForTokenClassification', 'TFXLMRobertaModel', 'TFXLMRobertaPreTrainedModel', 'TFXLMWithLMHeadModel', 'TFXLNetForMultipleChoice', 'TFXLNetForQuestionAnsweringSimple', 'TFXLNetForSequenceClassification', 'TFXLNetForTokenClassification', 'TFXLNetLMHeadModel', 'TFXLNetMainLayer', 'TFXLNetModel', 'TFXLNetPreTrainedModel', 'TF_ALBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_BERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_BLIP_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_CAMEMBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_CLIP_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_CONVBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_CTRL_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_CVT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_DEBERTA_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_DEBERTA_V2_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_DEIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_DISTILBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_DPR_CONTEXT_ENCODER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_DPR_QUESTION_ENCODER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_DPR_READER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_EFFICIENTFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_ELECTRA_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_FLAUBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_FUNNEL_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_GPT2_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_GROUPVIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_HUBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_LAYOUTLMV3_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_LAYOUTLM_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_LONGFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_LXMERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_MOBILEBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_MOBILEVIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING', 'TF_MODEL_FOR_CAUSAL_LM_MAPPING', 'TF_MODEL_FOR_DOCUMENT_QUESTION_ANSWERING_MAPPING', 'TF_MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING', 'TF_MODEL_FOR_MASKED_IMAGE_MODELING_MAPPING', 'TF_MODEL_FOR_MASKED_LM_MAPPING', 'TF_MODEL_FOR_MASK_GENERATION_MAPPING', 'TF_MODEL_FOR_MULTIPLE_CHOICE_MAPPING', 'TF_MODEL_FOR_NEXT_SENTENCE_PREDICTION_MAPPING', 'TF_MODEL_FOR_PRETRAINING_MAPPING', 'TF_MODEL_FOR_QUESTION_ANSWERING_MAPPING', 'TF_MODEL_FOR_SEMANTIC_SEGMENTATION_MAPPING', 'TF_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING', 'TF_MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING', 'TF_MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING', 'TF_MODEL_FOR_TABLE_QUESTION_ANSWERING_MAPPING', 'TF_MODEL_FOR_TEXT_ENCODING_MAPPING', 'TF_MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING', 'TF_MODEL_FOR_VISION_2_SEQ_MAPPING', 'TF_MODEL_FOR_ZERO_SHOT_IMAGE_CLASSIFICATION_MAPPING', 'TF_MODEL_MAPPING', 'TF_MODEL_WITH_LM_HEAD_MAPPING', 'TF_MPNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_OPENAI_GPT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_REGNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_REMBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_RESNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_ROBERTA_PRELAYERNORM_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_ROFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_SAM_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_SEGFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_SPEECH_TO_TEXT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_SWIN_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_T5_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_TAPAS_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_TRANSFO_XL_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_WAV_2_VEC_2_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_WEIGHTS_NAME', 'TF_WHISPER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_XGLM_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_XLM_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_XLM_ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_XLNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'TIMESFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'TIMESFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TIME_SERIES_TRANSFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'TIME_SERIES_TRANSFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TOKENIZER_MAPPING', 'TRAJECTORY_TRANSFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'TRAJECTORY_TRANSFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TRANSFORMERS_CACHE', 'TRANSFO_XL_PRETRAINED_CONFIG_ARCHIVE_MAP', 'TRANSFO_XL_PRETRAINED_MODEL_ARCHIVE_LIST', 'TROCR_PRETRAINED_CONFIG_ARCHIVE_MAP', 'TROCR_PRETRAINED_MODEL_ARCHIVE_LIST', 'TVLT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'TVLT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TVP_PRETRAINED_CONFIG_ARCHIVE_MAP', 'TVP_PRETRAINED_MODEL_ARCHIVE_LIST', 'TableQuestionAnsweringPipeline', 'TableTransformerConfig', 'TableTransformerForObjectDetection', 'TableTransformerModel', 'TableTransformerPreTrainedModel', 'TapasConfig', 'TapasForMaskedLM', 'TapasForQuestionAnswering', 'TapasForSequenceClassification', 'TapasModel', 'TapasPreTrainedModel', 'TapasTokenizer', 'TapexTokenizer', 'TemperatureLogitsWarper', 'TensorFlowBenchmark', 'TensorFlowBenchmarkArguments', 'TensorType', 'Text2TextGenerationPipeline', 'TextClassificationPipeline', 'TextDataset', 'TextDatasetForNextSentencePrediction', 'TextGenerationPipeline', 'TextIteratorStreamer', 'TextStreamer', 'TextToAudioPipeline', 'TimeSeriesTransformerConfig', 'TimeSeriesTransformerForPrediction', 'TimeSeriesTransformerModel', 'TimeSeriesTransformerPreTrainedModel', 'TimesformerConfig', 'TimesformerForVideoClassification', 'TimesformerModel', 'TimesformerPreTrainedModel', 'TimmBackbone', 'TimmBackboneConfig', 'TokenClassificationPipeline', 'TokenSpan', 'Tool', 'TopKLogitsWarper', 'TopPLogitsWarper', 'TrOCRConfig', 'TrOCRForCausalLM', 'TrOCRPreTrainedModel', 'TrOCRProcessor', 'Trainer', 'TrainerCallback', 'TrainerControl', 'TrainerState', 'TrainingArguments', 'TrajectoryTransformerConfig', 'TrajectoryTransformerModel', 'TrajectoryTransformerPreTrainedModel', 'TransfoXLConfig', 'TransfoXLCorpus', 'TransfoXLForSequenceClassification', 'TransfoXLLMHeadModel', 'TransfoXLModel', 'TransfoXLPreTrainedModel', 'TransfoXLTokenizer', 'TranslationPipeline', 'TvltConfig', 'TvltFeatureExtractor', 'TvltForAudioVisualClassification', 'TvltForPreTraining', 'TvltImageProcessor', 'TvltModel', 'TvltPreTrainedModel', 'TvltProcessor', 'TvpConfig', 'TvpForVideoGrounding', 'TvpImageProcessor', 'TvpModel', 'TvpPreTrainedModel', 'TvpProcessor', 'TypicalLogitsWarper', 'UMT5Config', 'UMT5EncoderModel', 'UMT5ForConditionalGeneration', 'UMT5ForQuestionAnswering', 'UMT5ForSequenceClassification', 'UMT5ForTokenClassification', 'UMT5Model', 'UMT5PreTrainedModel', 'UNISPEECH_PRETRAINED_CONFIG_ARCHIVE_MAP', 'UNISPEECH_PRETRAINED_MODEL_ARCHIVE_LIST', 'UNISPEECH_SAT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'UNISPEECH_SAT_PRETRAINED_MODEL_ARCHIVE_LIST', 'UNIVNET_PRETRAINED_CONFIG_ARCHIVE_MAP', 'UNIVNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'UnbatchedClassifierFreeGuidanceLogitsProcessor', 'UniSpeechConfig', 'UniSpeechForCTC', 'UniSpeechForPreTraining', 'UniSpeechForSequenceClassification', 'UniSpeechModel', 'UniSpeechPreTrainedModel', 'UniSpeechSatConfig', 'UniSpeechSatForAudioFrameClassification', 'UniSpeechSatForCTC', 'UniSpeechSatForPreTraining', 'UniSpeechSatForSequenceClassification', 'UniSpeechSatForXVector', 'UniSpeechSatModel', 'UniSpeechSatPreTrainedModel', 'UnivNetConfig', 'UnivNetFeatureExtractor', 'UnivNetModel', 'UperNetConfig', 'UperNetForSemanticSegmentation', 'UperNetPreTrainedModel', 'VAN_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VAN_PRETRAINED_MODEL_ARCHIVE_LIST', 'VIDEOMAE_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VIDEOMAE_PRETRAINED_MODEL_ARCHIVE_LIST', 'VILT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VILT_PRETRAINED_MODEL_ARCHIVE_LIST', 'VIPLLAVA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VIPLLAVA_PRETRAINED_MODEL_ARCHIVE_LIST', 'VISUAL_BERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VISUAL_BERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'VITDET_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VITDET_PRETRAINED_MODEL_ARCHIVE_LIST', 'VITMATTE_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VITMATTE_PRETRAINED_MODEL_ARCHIVE_LIST', 'VITS_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VITS_PRETRAINED_MODEL_ARCHIVE_LIST', 'VIT_HYBRID_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VIT_HYBRID_PRETRAINED_MODEL_ARCHIVE_LIST', 'VIT_MAE_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VIT_MAE_PRETRAINED_MODEL_ARCHIVE_LIST', 'VIT_MSN_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VIT_MSN_PRETRAINED_MODEL_ARCHIVE_LIST', 'VIT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'VIVIT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VIVIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'VanConfig', 'VanForImageClassification', 'VanModel', 'VanPreTrainedModel', 'ViTConfig', 'ViTFeatureExtractor', 'ViTForImageClassification', 'ViTForMaskedImageModeling', 'ViTHybridConfig', 'ViTHybridForImageClassification', 'ViTHybridImageProcessor', 'ViTHybridModel', 'ViTHybridPreTrainedModel', 'ViTImageProcessor', 'ViTMAEConfig', 'ViTMAEForPreTraining', 'ViTMAELayer', 'ViTMAEModel', 'ViTMAEPreTrainedModel', 'ViTMSNConfig', 'ViTMSNForImageClassification', 'ViTMSNModel', 'ViTMSNPreTrainedModel', 'ViTModel', 'ViTPreTrainedModel', 'VideoClassificationPipeline', 'VideoMAEConfig', 'VideoMAEFeatureExtractor', 'VideoMAEForPreTraining', 'VideoMAEForVideoClassification', 'VideoMAEImageProcessor', 'VideoMAEModel', 'VideoMAEPreTrainedModel', 'ViltConfig', 'ViltFeatureExtractor', 'ViltForImageAndTextRetrieval', 'ViltForImagesAndTextClassification', 'ViltForMaskedLM', 'ViltForQuestionAnswering', 'ViltForTokenClassification', 'ViltImageProcessor', 'ViltLayer', 'ViltModel', 'ViltPreTrainedModel', 'ViltProcessor', 'VipLlavaConfig', 'VipLlavaForConditionalGeneration', 'VipLlavaPreTrainedModel', 'VisionEncoderDecoderConfig', 'VisionEncoderDecoderModel', 'VisionTextDualEncoderConfig', 'VisionTextDualEncoderModel', 'VisionTextDualEncoderProcessor', 'VisualBertConfig', 'VisualBertForMultipleChoice', 'VisualBertForPreTraining', 'VisualBertForQuestionAnswering', 'VisualBertForRegionToPhraseAlignment', 'VisualBertForVisualReasoning', 'VisualBertLayer', 'VisualBertModel', 'VisualBertPreTrainedModel', 'VisualQuestionAnsweringPipeline', 'VitDetBackbone', 'VitDetConfig', 'VitDetModel', 'VitDetPreTrainedModel', 'VitMatteConfig', 'VitMatteForImageMatting', 'VitMatteImageProcessor', 'VitMattePreTrainedModel', 'VitsConfig', 'VitsModel', 'VitsPreTrainedModel', 'VitsTokenizer', 'VivitConfig', 'VivitForVideoClassification', 'VivitImageProcessor', 'VivitModel', 'VivitPreTrainedModel', 'WAV2VEC2_BERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'WAV2VEC2_BERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'WAV2VEC2_CONFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'WAV2VEC2_CONFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'WAVLM_PRETRAINED_CONFIG_ARCHIVE_MAP', 'WAVLM_PRETRAINED_MODEL_ARCHIVE_LIST', 'WAV_2_VEC_2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'WAV_2_VEC_2_PRETRAINED_MODEL_ARCHIVE_LIST', 'WEIGHTS_NAME', 'WHISPER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'WHISPER_PRETRAINED_MODEL_ARCHIVE_LIST', 'WarmUp', 'Wav2Vec2BertConfig', 'Wav2Vec2BertForAudioFrameClassification', 'Wav2Vec2BertForCTC', 'Wav2Vec2BertForSequenceClassification', 'Wav2Vec2BertForXVector', 'Wav2Vec2BertModel', 'Wav2Vec2BertPreTrainedModel', 'Wav2Vec2BertProcessor', 'Wav2Vec2CTCTokenizer', 'Wav2Vec2Config', 'Wav2Vec2ConformerConfig', 'Wav2Vec2ConformerForAudioFrameClassification', 'Wav2Vec2ConformerForCTC', 'Wav2Vec2ConformerForPreTraining', 'Wav2Vec2ConformerForSequenceClassification', 'Wav2Vec2ConformerForXVector', 'Wav2Vec2ConformerModel', 'Wav2Vec2ConformerPreTrainedModel', 'Wav2Vec2FeatureExtractor', 'Wav2Vec2ForAudioFrameClassification', 'Wav2Vec2ForCTC', 'Wav2Vec2ForMaskedLM', 'Wav2Vec2ForPreTraining', 'Wav2Vec2ForSequenceClassification', 'Wav2Vec2ForXVector', 'Wav2Vec2Model', 'Wav2Vec2PhonemeCTCTokenizer', 'Wav2Vec2PreTrainedModel', 'Wav2Vec2Processor', 'Wav2Vec2ProcessorWithLM', 'Wav2Vec2Tokenizer', 'WavLMConfig', 'WavLMForAudioFrameClassification', 'WavLMForCTC', 'WavLMForSequenceClassification', 'WavLMForXVector', 'WavLMModel', 'WavLMPreTrainedModel', 'WhisperConfig', 'WhisperFeatureExtractor', 'WhisperForAudioClassification', 'WhisperForCausalLM', 'WhisperForConditionalGeneration', 'WhisperModel', 'WhisperPreTrainedModel', 'WhisperProcessor', 'WhisperTimeStampLogitsProcessor', 'WhisperTokenizer', 'WhisperTokenizerFast', 'WordpieceTokenizer', 'XCLIPConfig', 'XCLIPModel', 'XCLIPPreTrainedModel', 'XCLIPProcessor', 'XCLIPTextConfig', 'XCLIPTextModel', 'XCLIPVisionConfig', 'XCLIPVisionModel', 'XCLIP_PRETRAINED_CONFIG_ARCHIVE_MAP', 'XCLIP_PRETRAINED_MODEL_ARCHIVE_LIST', 'XGLMConfig', 'XGLMForCausalLM', 'XGLMModel', 'XGLMPreTrainedModel', 'XGLMTokenizer', 'XGLMTokenizerFast', 'XGLM_PRETRAINED_CONFIG_ARCHIVE_MAP', 'XGLM_PRETRAINED_MODEL_ARCHIVE_LIST', 'XLMConfig', 'XLMForMultipleChoice', 'XLMForQuestionAnswering', 'XLMForQuestionAnsweringSimple', 'XLMForSequenceClassification', 'XLMForTokenClassification', 'XLMModel', 'XLMPreTrainedModel', 'XLMProphetNetConfig', 'XLMProphetNetDecoder', 'XLMProphetNetEncoder', 'XLMProphetNetForCausalLM', 'XLMProphetNetForConditionalGeneration', 'XLMProphetNetModel', 'XLMProphetNetPreTrainedModel', 'XLMProphetNetTokenizer', 'XLMRobertaConfig', 'XLMRobertaForCausalLM', 'XLMRobertaForMaskedLM', 'XLMRobertaForMultipleChoice', 'XLMRobertaForQuestionAnswering', 'XLMRobertaForSequenceClassification', 'XLMRobertaForTokenClassification', 'XLMRobertaModel', 'XLMRobertaPreTrainedModel', 'XLMRobertaTokenizer', 'XLMRobertaTokenizerFast', 'XLMRobertaXLConfig', 'XLMRobertaXLForCausalLM', 'XLMRobertaXLForMaskedLM', 'XLMRobertaXLForMultipleChoice', 'XLMRobertaXLForQuestionAnswering', 'XLMRobertaXLForSequenceClassification', 'XLMRobertaXLForTokenClassification', 'XLMRobertaXLModel', 'XLMRobertaXLPreTrainedModel', 'XLMTokenizer', 'XLMWithLMHeadModel', 'XLM_PRETRAINED_CONFIG_ARCHIVE_MAP', 'XLM_PRETRAINED_MODEL_ARCHIVE_LIST', 'XLM_PROPHETNET_PRETRAINED_CONFIG_ARCHIVE_MAP', 'XLM_PROPHETNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'XLM_ROBERTA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'XLM_ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST', 'XLM_ROBERTA_XL_PRETRAINED_CONFIG_ARCHIVE_MAP', 'XLM_ROBERTA_XL_PRETRAINED_MODEL_ARCHIVE_LIST', 'XLNET_PRETRAINED_CONFIG_ARCHIVE_MAP', 'XLNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'XLNetConfig', 'XLNetForMultipleChoice', 'XLNetForQuestionAnswering', 'XLNetForQuestionAnsweringSimple', 'XLNetForSequenceClassification', 'XLNetForTokenClassification', 'XLNetLMHeadModel', 'XLNetModel', 'XLNetPreTrainedModel', 'XLNetTokenizer', 'XLNetTokenizerFast', 'XMOD_PRETRAINED_CONFIG_ARCHIVE_MAP', 'XMOD_PRETRAINED_MODEL_ARCHIVE_LIST', 'XmodConfig', 'XmodForCausalLM', 'XmodForMaskedLM', 'XmodForMultipleChoice', 'XmodForQuestionAnswering', 'XmodForSequenceClassification', 'XmodForTokenClassification', 'XmodModel', 'XmodPreTrainedModel', 'YOLOS_PRETRAINED_CONFIG_ARCHIVE_MAP', 'YOLOS_PRETRAINED_MODEL_ARCHIVE_LIST', 'YOSO_PRETRAINED_CONFIG_ARCHIVE_MAP', 'YOSO_PRETRAINED_MODEL_ARCHIVE_LIST', 'YolosConfig', 'YolosFeatureExtractor', 'YolosForObjectDetection', 'YolosImageProcessor', 'YolosModel', 'YolosPreTrainedModel', 'YosoConfig', 'YosoForMaskedLM', 'YosoForMultipleChoice', 'YosoForQuestionAnswering', 'YosoForSequenceClassification', 'YosoForTokenClassification', 'YosoLayer', 'YosoModel', 'YosoPreTrainedModel', 'ZeroShotAudioClassificationPipeline', 'ZeroShotClassificationPipeline', 'ZeroShotImageClassificationPipeline', 'ZeroShotObjectDetectionPipeline', '__all__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_class_to_module', '_import_structure', '_modules', '_name', '_objects', 'activations', 'add_end_docstrings', 'add_start_docstrings', 'apply_chunking_to_forward', 'audio_utils', 'benchmark', 'benchmark.benchmark', 'benchmark.benchmark_args', 'cache_utils', 'commands', 'configuration_utils', 'convert_graph_to_onnx', 'convert_slow_tokenizer', 'convert_slow_tokenizers_checkpoints_to_fast', 'convert_tf_hub_seq_to_seq_bert_to_pytorch', 'convert_tf_weight_name_to_pt_weight_name', 'create_optimizer', 'data', 'data.data_collator', 'data.datasets', 'data.metrics', 'data.processors', 'debug_utils', 'deepspeed', 'default_data_collator', 'dependency_versions_check', 'dependency_versions_table', 'dynamic_module_utils', 'enable_full_determinism', 'feature_extraction_sequence_utils', 'feature_extraction_utils', 'file_utils', 'generation', 'generation_utils', 'get_constant_schedule', 'get_constant_schedule_with_warmup', 'get_cosine_schedule_with_warmup', 'get_cosine_with_hard_restarts_schedule_with_warmup', 'get_inverse_sqrt_schedule', 'get_linear_schedule_with_warmup', 'get_polynomial_decay_schedule_with_warmup', 'get_scheduler', 'glue_compute_metrics', 'glue_convert_examples_to_features', 'glue_output_modes', 'glue_processors', 'glue_tasks_num_labels', 'hf_argparser', 'hyperparameter_search', 'image_processing_utils', 'image_transforms', 'image_utils', 'integrations', 'is_apex_available', 'is_bitsandbytes_available', 'is_clearml_available', 'is_comet_available', 'is_datasets_available', 'is_decord_available', 'is_dvclive_available', 'is_faiss_available', 'is_flax_available', 'is_keras_nlp_available', 'is_neptune_available', 'is_optuna_available', 'is_phonemizer_available', 'is_psutil_available', 'is_py3nvml_available', 'is_pyctcdecode_available', 'is_ray_available', 'is_ray_tune_available', 'is_safetensors_available', 'is_scipy_available', 'is_sentencepiece_available', 'is_sigopt_available', 'is_sklearn_available', 'is_speech_available', 'is_tensorboard_available', 'is_tensorflow_text_available', 'is_tf_available', 'is_timm_available', 'is_tokenizers_available', 'is_torch_available', 'is_torch_neuroncore_available', 'is_torch_npu_available', 'is_torch_tpu_available', 'is_torch_xpu_available', 'is_torchvision_available', 'is_vision_available', 'is_wandb_available', 'launch_gradio_demo', 'load_pytorch_checkpoint_in_tf2_model', 'load_pytorch_model_in_tf2_model', 'load_pytorch_weights_in_tf2_model', 'load_tf2_checkpoint_in_pytorch_model', 'load_tf2_model_in_pytorch_model', 'load_tf2_weights_in_pytorch_model', 'load_tf_weights_in_albert', 'load_tf_weights_in_bert', 'load_tf_weights_in_bert_generation', 'load_tf_weights_in_big_bird', 'load_tf_weights_in_canine', 'load_tf_weights_in_convbert', 'load_tf_weights_in_electra', 'load_tf_weights_in_funnel', 'load_tf_weights_in_gpt2', 'load_tf_weights_in_gpt_neo', 'load_tf_weights_in_imagegpt', 'load_tf_weights_in_mobilebert', 'load_tf_weights_in_mobilenet_v1', 'load_tf_weights_in_mobilenet_v2', 'load_tf_weights_in_openai_gpt', 'load_tf_weights_in_qdqbert', 'load_tf_weights_in_realm', 'load_tf_weights_in_rembert', 'load_tf_weights_in_roc_bert', 'load_tf_weights_in_roformer', 'load_tf_weights_in_t5', 'load_tf_weights_in_tapas', 'load_tf_weights_in_transfo_xl', 'load_tf_weights_in_xlnet', 'load_tool', 'logging', 'modelcard', 'modeling_attn_mask_utils', 'modeling_outputs', 'modeling_tf_pytorch_utils', 'modeling_utils', 'models', 'models.albert', 'models.align', 'models.altclip', 'models.audio_spectrogram_transformer', 'models.auto', 'models.autoformer', 'models.bark', 'models.bart', 'models.barthez', 'models.bartpho', 'models.beit', 'models.bert', 'models.bert_generation', 'models.bert_japanese', 'models.bertweet', 'models.big_bird', 'models.bigbird_pegasus', 'models.biogpt', 'models.bit', 'models.blenderbot', 'models.blenderbot_small', 'models.blip', 'models.blip_2', 'models.bloom', 'models.bridgetower', 'models.bros', 'models.byt5', 'models.camembert', 'models.canine', 'models.chinese_clip', 'models.clap', 'models.clip', 'models.clipseg', 'models.clvp', 'models.code_llama', 'models.codegen', 'models.conditional_detr', 'models.convbert', 'models.convnext', 'models.convnextv2', 'models.cpm', 'models.cpmant', 'models.ctrl', 'models.cvt', 'models.data2vec', 'models.deberta', 'models.deberta_v2', 'models.decision_transformer', 'models.deformable_detr', 'models.deit', 'models.deprecated', 'models.deprecated.bort', 'models.deprecated.mctct', 'models.deprecated.mmbt', 'models.deprecated.open_llama', 'models.deprecated.retribert', 'models.deprecated.tapex', 'models.deprecated.trajectory_transformer', 'models.deprecated.transfo_xl', 'models.deprecated.van', 'models.depth_anything', 'models.deta', 'models.detr', 'models.dialogpt', 'models.dinat', 'models.dinov2', 'models.distilbert', 'models.dit', 'models.donut', 'models.dpr', 'models.dpt', 'models.efficientformer', 'models.efficientnet', 'models.electra', 'models.encodec', 'models.encoder_decoder', 'models.ernie', 'models.ernie_m', 'models.esm', 'models.falcon', 'models.fastspeech2_conformer', 'models.flaubert', 'models.flava', 'models.fnet', 'models.focalnet', 'models.fsmt', 'models.funnel', 'models.fuyu', 'models.git', 'models.glpn', 'models.gpt2', 'models.gpt_bigcode', 'models.gpt_neo', 'models.gpt_neox', 'models.gpt_neox_japanese', 'models.gpt_sw3', 'models.gptj', 'models.gptsan_japanese', 'models.graphormer', 'models.groupvit', 'models.herbert', 'models.hubert', 'models.ibert', 'models.idefics', 'models.imagegpt', 'models.informer', 'models.instructblip', 'models.jukebox', 'models.kosmos2', 'models.layoutlm', 'models.layoutlmv2', 'models.layoutlmv3', 'models.layoutxlm', 'models.led', 'models.levit', 'models.lilt', 'models.llama', 'models.llava', 'models.longformer', 'models.longt5', 'models.luke', 'models.lxmert', 'models.m2m_100', 'models.marian', 'models.markuplm', 'models.mask2former', 'models.maskformer', 'models.mbart', 'models.mbart50', 'models.mega', 'models.megatron_bert', 'models.megatron_gpt2', 'models.mgp_str', 'models.mistral', 'models.mixtral', 'models.mluke', 'models.mobilebert', 'models.mobilenet_v1', 'models.mobilenet_v2', 'models.mobilevit', 'models.mobilevitv2', 'models.mpnet', 'models.mpt', 'models.mra', 'models.mt5', 'models.musicgen', 'models.mvp', 'models.nat', 'models.nezha', 'models.nllb', 'models.nllb_moe', 'models.nougat', 'models.nystromformer', 'models.oneformer', 'models.openai', 'models.opt', 'models.owlv2', 'models.owlvit', 'models.patchtsmixer', 'models.patchtst', 'models.pegasus', 'models.pegasus_x', 'models.perceiver', 'models.persimmon', 'models.phi', 'models.phobert', 'models.pix2struct', 'models.plbart', 'models.poolformer', 'models.pop2piano', 'models.prophetnet', 'models.pvt', 'models.qdqbert', 'models.qwen2', 'models.rag', 'models.realm', 'models.reformer', 'models.regnet', 'models.rembert', 'models.resnet', 'models.roberta', 'models.roberta_prelayernorm', 'models.roc_bert', 'models.roformer', 'models.rwkv', 'models.sam', 'models.seamless_m4t', 'models.seamless_m4t_v2', 'models.segformer', 'models.sew', 'models.sew_d', 'models.siglip', 'models.speech_encoder_decoder', 'models.speech_to_text', 'models.speech_to_text_2', 'models.speecht5', 'models.splinter', 'models.squeezebert', 'models.stablelm', 'models.swiftformer', 'models.swin', 'models.swin2sr', 'models.swinv2', 'models.switch_transformers', 'models.t5', 'models.table_transformer', 'models.tapas', 'models.time_series_transformer', 'models.timesformer', 'models.timm_backbone', 'models.trocr', 'models.tvlt', 'models.tvp', 'models.umt5', 'models.unispeech', 'models.unispeech_sat', 'models.univnet', 'models.upernet', 'models.videomae', 'models.vilt', 'models.vipllava', 'models.vision_encoder_decoder', 'models.vision_text_dual_encoder', 'models.visual_bert', 'models.vit', 'models.vit_hybrid', 'models.vit_mae', 'models.vit_msn', 'models.vitdet', 'models.vitmatte', 'models.vits', 'models.vivit', 'models.wav2vec2', 'models.wav2vec2_bert', 'models.wav2vec2_conformer', 'models.wav2vec2_phoneme', 'models.wav2vec2_with_lm', 'models.wavlm', 'models.whisper', 'models.x_clip', 'models.xglm', 'models.xlm', 'models.xlm_prophetnet', 'models.xlm_roberta', 'models.xlm_roberta_xl', 'models.xlnet', 'models.xmod', 'models.yolos', 'models.yoso', 'onnx', 'optimization', 'pipeline', 'pipelines', 'processing_utils', 'prune_layer', 'pytorch_utils', 'quantizers', 'requires_backends', 'sagemaker', 'set_seed', 'shape_list', 'squad_convert_examples_to_features', 'testing_utils', 'tf_top_k_top_p_filtering', 'time_series_utils', 'tokenization_utils', 'tokenization_utils_base', 'tokenization_utils_fast', 'tools', 'top_k_top_p_filtering', 'torch_distributed_zero_first', 'trainer', 'trainer_callback', 'trainer_pt_utils', 'trainer_seq2seq', 'trainer_utils', 'training_args', 'training_args_seq2seq', 'training_args_tf', 'utils', 'utils.dummy_essentia_and_librosa_and_pretty_midi_and_scipy_and_torch_objects', 'utils.dummy_flax_objects', 'utils.dummy_keras_nlp_objects', 'utils.dummy_sentencepiece_and_tokenizers_objects', 'utils.dummy_sentencepiece_objects', 'utils.dummy_tensorflow_text_objects', 'utils.dummy_tf_objects', 'utils.quantization_config', 'xnli_compute_metrics', 'xnli_output_modes', 'xnli_processors', 'xnli_tasks_num_labels']\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "# Print out the available modules in transformers\n",
    "print(dir(transformers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0526c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\sahil\\anaconda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "\n",
    "class Mistral7B(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        tokenizer\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        model = self.load_model()\n",
    "\n",
    "        #device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "        model_inputs = self.tokenizer([prompt], return_tensors=\"pt\")#.to(device)\n",
    "        #model.to(device)\n",
    "\n",
    "        generated_ids = model.generate(**model_inputs, max_new_tokens=100, do_sample=True)\n",
    "        return self.tokenizer.batch_decode(generated_ids)[0]\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        return self.generate(prompt)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"MiniLM\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/MiniLM-L12-H384-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/MiniLM-L12-H384-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a372b17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] write me a joke [SEP] pornography distance brooks sustainedlow territory quantities drive sensory warner dodge sustained property envelope completelyrk flat network mls ruralxi quantities barbara contact windshield overlooked connectedsson production campus haas financially pace la comics conclusion serves luxury occasional coverage valuedrca destinations au exclusivelyfin close manner solelyzione los lies viewuansf unlimited endorsed valuedvr delegation barely delegation preceded les teatrolier connection lecpace wal league emissionsovers fours wisconsin multimediaovers medicare costs boundary rural age haul transatlantic league affiliateosphere helps neutrality recognition slate ex format ac dl luxury processhouse serie\n"
     ]
    }
   ],
   "source": [
    "mistral_7b = Mistral7B(model=model, tokenizer=tokenizer)\n",
    "print(mistral_7b.generate(\"Write me a joke\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d041e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "...\n",
    "\n",
    "metric = AnswerRelevancyMetric(model=mistral_7b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a55401cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'truths'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\deepeval\\metrics\\faithfulness\\faithfulness.py:236\u001b[0m, in \u001b[0;36mFaithfulnessMetric._a_generate_truths\u001b[1;34m(self, retrieval_context)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 236\u001b[0m     res: Truths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39ma_generate(prompt, schema\u001b[38;5;241m=\u001b[39mTruths)\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mtruths\n",
      "\u001b[1;31mTypeError\u001b[0m: Mistral7B.a_generate() got an unexpected keyword argument 'schema'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 22\u001b[0m\n\u001b[0;32m     11\u001b[0m metric \u001b[38;5;241m=\u001b[39m FaithfulnessMetric(\n\u001b[0;32m     12\u001b[0m     threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[0;32m     13\u001b[0m     model\u001b[38;5;241m=\u001b[39mmistral_7b,\n\u001b[0;32m     14\u001b[0m     include_reason\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     16\u001b[0m test_case \u001b[38;5;241m=\u001b[39m LLMTestCase(\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat if these shoes don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt fit?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m     actual_output\u001b[38;5;241m=\u001b[39mactual_output,\n\u001b[0;32m     19\u001b[0m     retrieval_context\u001b[38;5;241m=\u001b[39mretrieval_context\n\u001b[0;32m     20\u001b[0m )\n\u001b[1;32m---> 22\u001b[0m metric\u001b[38;5;241m.\u001b[39mmeasure(test_case)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(metric\u001b[38;5;241m.\u001b[39mscore)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(metric\u001b[38;5;241m.\u001b[39mreason)\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\deepeval\\metrics\\faithfulness\\faithfulness.py:56\u001b[0m, in \u001b[0;36mFaithfulnessMetric.measure\u001b[1;34m(self, test_case, _show_indicator)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_mode:\n\u001b[0;32m     55\u001b[0m     loop \u001b[38;5;241m=\u001b[39m get_or_create_event_loop()\n\u001b[1;32m---> 56\u001b[0m     loop\u001b[38;5;241m.\u001b[39mrun_until_complete(\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma_measure(test_case, _show_indicator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     58\u001b[0m     )\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_truths(test_case\u001b[38;5;241m.\u001b[39mretrieval_context)\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\nest_asyncio.py:90\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\asyncio\\futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\asyncio\\tasks.py:269\u001b[0m, in \u001b[0;36mTask.__step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    267\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 269\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_must_cancel:\n\u001b[0;32m    272\u001b[0m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\deepeval\\metrics\\faithfulness\\faithfulness.py:89\u001b[0m, in \u001b[0;36mFaithfulnessMetric.a_measure\u001b[1;34m(self, test_case, _show_indicator)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musing_native_model \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m metric_progress_indicator(\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28mself\u001b[39m, async_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, _show_indicator\u001b[38;5;241m=\u001b[39m_show_indicator\n\u001b[0;32m     88\u001b[0m ):\n\u001b[1;32m---> 89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruths, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclaims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[0;32m     90\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_a_generate_truths(test_case\u001b[38;5;241m.\u001b[39mretrieval_context),\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_a_generate_claims(test_case\u001b[38;5;241m.\u001b[39mactual_output),\n\u001b[0;32m     92\u001b[0m     )\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverdicts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_a_generate_verdicts()\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_score()\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\asyncio\\tasks.py:339\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 339\u001b[0m         future\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    341\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\asyncio\\tasks.py:267\u001b[0m, in \u001b[0;36mTask.__step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\deepeval\\metrics\\faithfulness\\faithfulness.py:241\u001b[0m, in \u001b[0;36mFaithfulnessMetric._a_generate_truths\u001b[1;34m(self, retrieval_context)\u001b[0m\n\u001b[0;32m    239\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39ma_generate(prompt)\n\u001b[0;32m    240\u001b[0m data \u001b[38;5;241m=\u001b[39m trimAndLoadJson(res, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 241\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruths\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'truths'"
     ]
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import FaithfulnessMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "# Replace this with the actual output from your LLM application\n",
    "actual_output = \"We offer a 30-day full refund at no extra cost.\"\n",
    "\n",
    "# Replace this with the actual retrieved context from your RAG pipeline\n",
    "retrieval_context = [\"All customers are eligible for a 30 day full refund at no extra cost.\"]\n",
    "\n",
    "metric = FaithfulnessMetric(\n",
    "    threshold=0.7,\n",
    "    model=mistral_7b,\n",
    "    include_reason=True\n",
    ")\n",
    "test_case = LLMTestCase(\n",
    "    input=\"What if these shoes don't fit?\",\n",
    "    actual_output=actual_output,\n",
    "    retrieval_context=retrieval_context\n",
    ")\n",
    "\n",
    "metric.measure(test_case)\n",
    "print(metric.score)\n",
    "print(metric.reason)\n",
    "\n",
    "# or evaluate test cases in bulk\n",
    "evaluate([test_case], [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50e06700",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5aaf9b128194694acb2b261c33ee489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahil\\anaconda\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sahil\\.cache\\huggingface\\hub\\models--mistralai--Mistral-7B-v0.1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-v0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m, device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-v0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMy favourite condiment is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    563\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    564\u001b[0m     )\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m--> 566\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    568\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    569\u001b[0m     )\n\u001b[0;32m    570\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    573\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:387\u001b[0m, in \u001b[0;36m_get_model_class\u001b[1;34m(config, model_mapping)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_model_class\u001b[39m(config, model_mapping):\n\u001b[1;32m--> 387\u001b[0m     supported_models \u001b[38;5;241m=\u001b[39m model_mapping[\u001b[38;5;28mtype\u001b[39m(config)]\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(supported_models, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m supported_models\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:738\u001b[0m, in \u001b[0;36m_LazyAutoMapping.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping:\n\u001b[0;32m    737\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping[model_type]\n\u001b[1;32m--> 738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_attr_from_module(model_type, model_name)\n\u001b[0;32m    740\u001b[0m \u001b[38;5;66;03m# Maybe there was several model types associated with this config.\u001b[39;00m\n\u001b[0;32m    741\u001b[0m model_types \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_mapping\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;241m==\u001b[39m key\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:752\u001b[0m, in \u001b[0;36m_LazyAutoMapping._load_attr_from_module\u001b[1;34m(self, model_type, attr)\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[0;32m    751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[module_name] \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.models\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m getattribute_from_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[module_name], attr)\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:696\u001b[0m, in \u001b[0;36mgetattribute_from_module\u001b[1;34m(module, attr)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(attr, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(getattribute_from_module(module, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m attr)\n\u001b[1;32m--> 696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module, attr):\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, attr)\n\u001b[0;32m    698\u001b[0m \u001b[38;5;66;03m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[39;00m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;66;03m# object at the top level.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1380\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1378\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1380\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   1381\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1382\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1390\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1389\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1390\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1391\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1392\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1393\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1394\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1395\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_attn_mask_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _prepare_4d_causal_attention_mask, _prepare_4d_causal_attention_mask_for_sdpa\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModelOutputWithPast, CausalLMOutputWithPast, SequenceClassifierOutputWithPast\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     38\u001b[0m     add_start_docstrings,\n\u001b[0;32m     39\u001b[0m     add_start_docstrings_to_model_forward,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m     replace_return_docstrings,\n\u001b[0;32m     44\u001b[0m )\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_mistral\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MistralConfig\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\transformers\\modeling_utils.py:44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m custom_object_save\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GenerationConfig, GenerationMixin\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftAdapterMixin, deepspeed_config, is_deepspeed_zero3_enabled\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     Conv1D,\n\u001b[0;32m     48\u001b[0m     apply_chunking_to_forward,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m     prune_linear_layer,\n\u001b[0;32m     55\u001b[0m )\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1380\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1378\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1380\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   1381\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1382\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1390\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1389\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1390\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1391\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1392\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1393\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1394\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1395\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\transformers\\generation\\utils.py:93\u001b[0m\n\u001b[0;32m     90\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_accelerate_available():\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AlignDevicesHook, add_hook_to_module\n\u001b[0;32m     95\u001b[0m NEED_SETUP_CACHE_CLASSES_MAPPING \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatic\u001b[39m\u001b[38;5;124m\"\u001b[39m: StaticCache,\n\u001b[0;32m     97\u001b[0m }\n\u001b[0;32m    100\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGenerateDecoderOnlyOutput\u001b[39;00m(ModelOutput):\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\accelerate\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.28.0.dev0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccelerator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Accelerator\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbig_modeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     cpu_offload,\n\u001b[0;32m      6\u001b[0m     cpu_offload_with_hook,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     load_checkpoint_and_dispatch,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m skip_first_batches\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\accelerate\\accelerator.py:35\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhooks\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpointing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoaderDispatcher, prepare_data_loader, skip_first_batches\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AlignDevicesHook\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\accelerate\\checkpointing.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msafetensors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_file\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mamp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradScaler\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     25\u001b[0m     MODEL_NAME,\n\u001b[0;32m     26\u001b[0m     OPTIMIZER_NAME,\n\u001b[0;32m     27\u001b[0m     RNG_STATE_NAME,\n\u001b[0;32m     28\u001b[0m     SAFE_MODEL_NAME,\n\u001b[0;32m     29\u001b[0m     SAFE_WEIGHTS_NAME,\n\u001b[0;32m     30\u001b[0m     SAMPLER_NAME,\n\u001b[0;32m     31\u001b[0m     SCALER_NAME,\n\u001b[0;32m     32\u001b[0m     SCHEDULER_NAME,\n\u001b[0;32m     33\u001b[0m     WEIGHTS_NAME,\n\u001b[0;32m     34\u001b[0m     get_pretty_name,\n\u001b[0;32m     35\u001b[0m     is_torch_xla_available,\n\u001b[0;32m     36\u001b[0m     is_xpu_available,\n\u001b[0;32m     37\u001b[0m     save,\n\u001b[0;32m     38\u001b[0m )\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_xla\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxla_model\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxm\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\accelerate\\utils\\__init__.py:159\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeepspeed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    150\u001b[0m         DeepSpeedEngineWrapper,\n\u001b[0;32m    151\u001b[0m         DeepSpeedOptimizerWrapper,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m         HfDeepSpeedConfig,\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbnb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m has_4bit_bnb_layers, load_and_quantize_model\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_fsdp_model, load_fsdp_optimizer, save_fsdp_model, save_fsdp_optimizer\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlaunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    161\u001b[0m     PrepareForLaunch,\n\u001b[0;32m    162\u001b[0m     _filter_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m     prepare_tpu,\n\u001b[0;32m    168\u001b[0m )\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmegatron_lm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    170\u001b[0m     AbstractTrainStep,\n\u001b[0;32m    171\u001b[0m     BertTrainStep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    180\u001b[0m     gather_across_data_parallel_groups,\n\u001b[0;32m    181\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\accelerate\\utils\\fsdp_utils.py:26\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_torch_version\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;124m\"\u001b[39m, FSDP_PYTORCH_VERSION) \u001b[38;5;129;01mand\u001b[39;00m is_torch_distributed_available():\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdist_cp\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdefault_planner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DefaultLoadPlanner, DefaultSavePlanner\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_sharded_optimizer_state_dict\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\distributed\\checkpoint\\__init__.py:7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetadata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     TensorStorageMetadata,\n\u001b[0;32m      3\u001b[0m     BytesStorageMetadata,\n\u001b[0;32m      4\u001b[0m     ChunkStorageMetadata,\n\u001b[0;32m      5\u001b[0m     Metadata,\n\u001b[0;32m      6\u001b[0m )\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstate_dict_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_state_dict, load\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstate_dict_saver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_state_dict, save\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstorage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StorageReader, StorageWriter\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\distributed\\checkpoint\\state_dict_loader.py:12\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstorage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     StorageReader,\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplanner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoadPlanner\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdefault_planner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DefaultLoadPlanner\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _DistWrapper, _all_gather_keys\n\u001b[0;32m     16\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\distributed\\checkpoint\\default_planner.py:14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m narrow_tensor_by_index\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DTensor\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplanner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     18\u001b[0m     SavePlanner,\n\u001b[0;32m     19\u001b[0m     LoadPlanner,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     WriteItemType,\n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetadata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     BytesStorageMetadata,\n\u001b[0;32m     29\u001b[0m     ChunkStorageMetadata,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     STORAGE_TYPES,\n\u001b[0;32m     35\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\distributed\\_tensor\\__init__.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Import all builtin dist tensor ops\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_local_shape\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\distributed\\_tensor\\ops\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membedding_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmatrix_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmath_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\distributed\\_tensor\\ops\\embedding_ops.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# implement matrix related ops for distributed tensor\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mop_schema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpSchema, OutputSharding\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_prop_rule\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplacement_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     _Partial,\n\u001b[0;32m     10\u001b[0m     DTensorSpec,\n\u001b[0;32m     11\u001b[0m     Replicate,\n\u001b[0;32m     12\u001b[0m     Shard,\n\u001b[0;32m     13\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\distributed\\_tensor\\op_schema.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpOverload\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplacement_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DTensorSpec\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdevice_mesh\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeviceMesh\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\distributed\\_tensor\\placement_types.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, cast, List, NamedTuple, Optional, Tuple\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functional_collectives\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mfuncol\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed_c10d\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mc10d\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_collective_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mesh_broadcast, mesh_scatter\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\distributed\\_functional_collectives.py:26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 26\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexternal_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_compiling \u001b[38;5;28;01mas\u001b[39;00m is_torchdynamo_compiling\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m     28\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to import torchdynamo util `is_torchdynamo_compiling`, so won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support torchdynamo correctly\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\_dynamo\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m allowed_functions, convert_frame, eval_frame, resume_execution\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcode_context\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m code_context\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:45\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_transformation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     check_inst_exn_tab_entries_valid,\n\u001b[0;32m     34\u001b[0m     Instruction,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     transform_code_object,\n\u001b[0;32m     38\u001b[0m )\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache_size\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     40\u001b[0m     CacheSizeRelevantForFrame,\n\u001b[0;32m     41\u001b[0m     compute_cache_size,\n\u001b[0;32m     42\u001b[0m     exceeds_cache_size_limit,\n\u001b[0;32m     43\u001b[0m     is_recompilation,\n\u001b[0;32m     44\u001b[0m )\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meval_frame\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m always_optimize_code_objects, skip_code, TorchPatcher\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     47\u001b[0m     augment_exc_message,\n\u001b[0;32m     48\u001b[0m     BackendCompilerFailed,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m     Unsupported,\n\u001b[0;32m     55\u001b[0m )\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     57\u001b[0m     CheckFunctionManager,\n\u001b[0;32m     58\u001b[0m     get_and_maybe_log_recompilation_reason,\n\u001b[0;32m     59\u001b[0m     GuardedCode,\n\u001b[0;32m     60\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:69\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28mglobals\u001b[39m()[name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39meval_frame, name)\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, convert_frame, external_utils, skipfiles, utils\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcode_context\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m code_context\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CondOpArgsMismatchError, UserError, UserErrorType\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\_dynamo\\skipfiles.py:39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_content_store\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getfile\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     40\u001b[0m     NestedUserFunctionVariable,\n\u001b[0;32m     41\u001b[0m     UserFunctionVariable,\n\u001b[0;32m     42\u001b[0m     UserMethodVariable,\n\u001b[0;32m     43\u001b[0m )\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03mA note on skipfiles:\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;124;03myou don't want to inline them.\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     90\u001b[0m BUILTIN_SKIPLIST \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     91\u001b[0m     abc,\n\u001b[0;32m     92\u001b[0m     collections,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m     _weakrefset,\n\u001b[0;32m    122\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\_dynamo\\variables\\__init__.py:26\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdicts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     ConstDictVariable,\n\u001b[0;32m     16\u001b[0m     CustomizedDictVariable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     SetVariable,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     22\u001b[0m     NestedUserFunctionVariable,\n\u001b[0;32m     23\u001b[0m     UserFunctionVariable,\n\u001b[0;32m     24\u001b[0m     UserMethodVariable,\n\u001b[0;32m     25\u001b[0m )\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhigher_order_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TorchHigherOrderOperatorVariable\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     CountIteratorVariable,\n\u001b[0;32m     29\u001b[0m     CycleIteratorVariable,\n\u001b[0;32m     30\u001b[0m     IteratorVariable,\n\u001b[0;32m     31\u001b[0m     RepeatIteratorVariable,\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyVariableTracker\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\_dynamo\\variables\\higher_order_ops.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moperators\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dispatch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m enable_python_dispatcher\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy_to_fake_tensor, get_fake_value, get_real_value\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\onnx\\__init__.py:10\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _onnx \u001b[38;5;28;01mas\u001b[39;00m _C_onnx\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_onnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     _CAFFE2_ATEN_FALLBACK,\n\u001b[0;32m      5\u001b[0m     OperatorExportTypes,\n\u001b[0;32m      6\u001b[0m     TensorProtoDataType,\n\u001b[0;32m      7\u001b[0m     TrainingMode,\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort:skip. Keep the order instead of sorting lexicographically\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     _deprecation,\n\u001b[0;32m     12\u001b[0m     errors,\n\u001b[0;32m     13\u001b[0m     symbolic_caffe2,\n\u001b[0;32m     14\u001b[0m     symbolic_helper,\n\u001b[0;32m     15\u001b[0m     symbolic_opset7,\n\u001b[0;32m     16\u001b[0m     symbolic_opset8,\n\u001b[0;32m     17\u001b[0m     symbolic_opset9,\n\u001b[0;32m     18\u001b[0m     symbolic_opset10,\n\u001b[0;32m     19\u001b[0m     symbolic_opset11,\n\u001b[0;32m     20\u001b[0m     symbolic_opset12,\n\u001b[0;32m     21\u001b[0m     symbolic_opset13,\n\u001b[0;32m     22\u001b[0m     symbolic_opset14,\n\u001b[0;32m     23\u001b[0m     symbolic_opset15,\n\u001b[0;32m     24\u001b[0m     symbolic_opset16,\n\u001b[0;32m     25\u001b[0m     symbolic_opset17,\n\u001b[0;32m     26\u001b[0m     symbolic_opset18,\n\u001b[0;32m     27\u001b[0m     utils,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# TODO(After 1.13 release): Remove the deprecated SymbolicContext\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exporter_states\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExportTypes, SymbolicContext\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\onnx\\errors.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _C\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _constants\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m diagnostics\n\u001b[0;32m     11\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnnxExporterError\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnnxExporterWarning\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupportedOperatorError\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m ]\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mOnnxExporterWarning\u001b[39;00m(\u001b[38;5;167;01mUserWarning\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\onnx\\_internal\\diagnostics\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_diagnostic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     create_export_diagnostic_context,\n\u001b[0;32m      3\u001b[0m     diagnose,\n\u001b[0;32m      4\u001b[0m     engine,\n\u001b[0;32m      5\u001b[0m     export_context,\n\u001b[0;32m      6\u001b[0m     ExportDiagnosticEngine,\n\u001b[0;32m      7\u001b[0m     TorchScriptOnnxExportDiagnostic,\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rules\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfra\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m levels\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\onnx\\_internal\\diagnostics\\_diagnostic.py:11\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Optional\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiagnostics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infra\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiagnostics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfra\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m formatter, sarif\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiagnostics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msarif\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version \u001b[38;5;28;01mas\u001b[39;00m sarif_version\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\onnx\\_internal\\diagnostics\\infra\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_infra\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     DiagnosticOptions,\n\u001b[0;32m      3\u001b[0m     Graph,\n\u001b[0;32m      4\u001b[0m     Invocation,\n\u001b[0;32m      5\u001b[0m     Level,\n\u001b[0;32m      6\u001b[0m     levels,\n\u001b[0;32m      7\u001b[0m     Location,\n\u001b[0;32m      8\u001b[0m     Rule,\n\u001b[0;32m      9\u001b[0m     RuleCollection,\n\u001b[0;32m     10\u001b[0m     Stack,\n\u001b[0;32m     11\u001b[0m     StackFrame,\n\u001b[0;32m     12\u001b[0m     Tag,\n\u001b[0;32m     13\u001b[0m     ThreadFlowLocation,\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Diagnostic, DiagnosticContext, RuntimeErrorWithDiagnostic\n\u001b[0;32m     17\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiagnostic\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiagnosticContext\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThreadFlowLocation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     33\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\onnx\\_internal\\diagnostics\\infra\\_infra.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FrozenSet, List, Mapping, Optional, Sequence, Tuple\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiagnostics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfra\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m formatter, sarif\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLevel\u001b[39;00m(enum\u001b[38;5;241m.\u001b[39mIntEnum):\n\u001b[0;32m     14\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The level of a diagnostic.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    This class is used to represent the level of a diagnostic. The levels are defined\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m        Level.ERROR = logging.ERROR = 40\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\onnx\\_internal\\diagnostics\\infra\\formatter.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_logging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyString\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _beartype\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiagnostics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfra\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sarif\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# A list of types in the SARIF module to support pretty printing.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# This is solely for type annotation for the functions below.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m _SarifClass \u001b[38;5;241m=\u001b[39m Union[\n\u001b[0;32m     17\u001b[0m     sarif\u001b[38;5;241m.\u001b[39mSarifLog,\n\u001b[0;32m     18\u001b[0m     sarif\u001b[38;5;241m.\u001b[39mRun,\n\u001b[0;32m     19\u001b[0m     sarif\u001b[38;5;241m.\u001b[39mReportingDescriptor,\n\u001b[0;32m     20\u001b[0m     sarif\u001b[38;5;241m.\u001b[39mResult,\n\u001b[0;32m     21\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\onnx\\_internal\\diagnostics\\infra\\sarif\\__init__.py:18\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiagnostics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msarif\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_code_flow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CodeFlow\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiagnostics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msarif\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_configuration_override\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     ConfigurationOverride,\n\u001b[0;32m     17\u001b[0m )\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiagnostics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msarif\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_conversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conversion\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiagnostics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msarif\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_edge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Edge\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiagnostics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msarif\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_edge_traversal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EdgeTraversal\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\onnx\\_internal\\diagnostics\\infra\\sarif\\_conversion.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdataclasses\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Optional\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiagnostics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msarif\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     _artifact_location,\n\u001b[0;32m     11\u001b[0m     _invocation,\n\u001b[0;32m     12\u001b[0m     _property_bag,\n\u001b[0;32m     13\u001b[0m     _tool,\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     17\u001b[0m \u001b[38;5;129m@dataclasses\u001b[39m\u001b[38;5;241m.\u001b[39mdataclass\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mConversion\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[0;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Describes how a converter transformed the output of a static analysis tool from the analysis tool's native output format into the SARIF format.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\torch\\onnx\\_internal\\diagnostics\\infra\\sarif\\_invocation.py:17\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, List, Optional\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiagnostics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msarif\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     _artifact_location,\n\u001b[0;32m     11\u001b[0m     _configuration_override,\n\u001b[0;32m     12\u001b[0m     _notification,\n\u001b[0;32m     13\u001b[0m     _property_bag,\n\u001b[0;32m     14\u001b[0m )\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;129m@dataclasses\u001b[39m\u001b[38;5;241m.\u001b[39mdataclass\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInvocation\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[0;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The runtime environment of the analysis tool run.\"\"\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     execution_successful: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m dataclasses\u001b[38;5;241m.\u001b[39mfield(\n\u001b[0;32m     22\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschema_property_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecutionSuccessful\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     23\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\dataclasses.py:1230\u001b[0m, in \u001b[0;36mdataclass\u001b[1;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001b[0m\n\u001b[0;32m   1227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrap\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;66;03m# We're called as @dataclass without parens.\u001b[39;00m\n\u001b[1;32m-> 1230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\dataclasses.py:1220\u001b[0m, in \u001b[0;36mdataclass.<locals>.wrap\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;28mcls\u001b[39m):\n\u001b[1;32m-> 1220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _process_class(\u001b[38;5;28mcls\u001b[39m, init, \u001b[38;5;28mrepr\u001b[39m, eq, order, unsafe_hash,\n\u001b[0;32m   1221\u001b[0m                           frozen, match_args, kw_only, slots,\n\u001b[0;32m   1222\u001b[0m                           weakref_slot)\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\dataclasses.py:958\u001b[0m, in \u001b[0;36m_process_class\u001b[1;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001b[0m\n\u001b[0;32m    955\u001b[0m         kw_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    957\u001b[0m         \u001b[38;5;66;03m# Otherwise it's a field of some type.\u001b[39;00m\n\u001b[1;32m--> 958\u001b[0m         cls_fields\u001b[38;5;241m.\u001b[39mappend(_get_field(\u001b[38;5;28mcls\u001b[39m, name, \u001b[38;5;28mtype\u001b[39m, kw_only))\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m cls_fields:\n\u001b[0;32m    961\u001b[0m     fields[f\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m f\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\dataclasses.py:767\u001b[0m, in \u001b[0;36m_get_field\u001b[1;34m(cls, a_name, a_type, default_kw_only)\u001b[0m\n\u001b[0;32m    763\u001b[0m typing \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtyping\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typing:\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (_is_classvar(a_type, typing)\n\u001b[0;32m    766\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(f\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m--> 767\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m _is_type(f\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mcls\u001b[39m, typing, typing\u001b[38;5;241m.\u001b[39mClassVar,\n\u001b[0;32m    768\u001b[0m                          _is_classvar))):\n\u001b[0;32m    769\u001b[0m         f\u001b[38;5;241m.\u001b[39m_field_type \u001b[38;5;241m=\u001b[39m _FIELD_CLASSVAR\n\u001b[0;32m    771\u001b[0m \u001b[38;5;66;03m# If the type is InitVar, or if it's a matching string annotation,\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;66;03m# then it's an InitVar.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\dataclasses.py:705\u001b[0m, in \u001b[0;36m_is_type\u001b[1;34m(annotation, cls, a_module, a_type, is_type_predicate)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_type\u001b[39m(annotation, \u001b[38;5;28mcls\u001b[39m, a_module, a_type, is_type_predicate):\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;66;03m# Given a type annotation string, does it refer to a_type in\u001b[39;00m\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;66;03m# a_module?  For example, when checking that annotation denotes a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;66;03m# a eval() penalty for every single field of every dataclass\u001b[39;00m\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;66;03m# that's defined.  It was judged not worth it.\u001b[39;00m\n\u001b[1;32m--> 705\u001b[0m     match \u001b[38;5;241m=\u001b[39m _MODULE_IDENTIFIER_RE\u001b[38;5;241m.\u001b[39mmatch(annotation)\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m match:\n\u001b[0;32m    707\u001b[0m         ns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\", device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "\n",
    "prompt = \"My favourite condiment is\"\n",
    "\n",
    "model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
    "model.to(device)\n",
    "\n",
    "generated_ids = model.generate(**model_inputs, max_new_tokens=100, do_sample=True)\n",
    "tokenizer.batch_decode(generated_ids)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e63fa3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\sahil\\anaconda\\lib\\site-packages (0.20.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\sahil\\anaconda\\lib\\site-packages (from huggingface_hub) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from huggingface_hub) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\sahil\\anaconda\\lib\\site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from huggingface_hub) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sahil\\anaconda\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from requests->huggingface_hub) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from requests->huggingface_hub) (2023.7.22)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\sahil\\anaconda\\lib\\site-packages (0.20.3)\n",
      "Requirement already satisfied: transformers in c:\\users\\sahil\\anaconda\\lib\\site-packages (4.38.0.dev0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sahil\\anaconda\\lib\\site-packages (from huggingface_hub) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from huggingface_hub) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\sahil\\anaconda\\lib\\site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from huggingface_hub) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\sahil\\anaconda\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from requests->huggingface_hub) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from requests->huggingface_hub) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ede0c00",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\sahil\\anaconda\\lib\\site-packages (4.44.2)\n",
      "Requirement already satisfied: torch in c:\\users\\sahil\\anaconda\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\sahil\\anaconda\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\sahil\\anaconda\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\sahil\\anaconda\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sahil\\anaconda\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sahil\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Found existing installation: transformers 4.44.2\n",
      "Uninstalling transformers-4.44.2:\n",
      "  Successfully uninstalled transformers-4.44.2\n",
      "Collecting transformers\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/75/35/07c9879163b603f0e464b0f6e6e628a2340cfc7cdc5ca8e7d52d776710d4/transformers-4.44.2-py3-none-any.whl.metadata\n",
      "  Using cached transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\sahil\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sahil\\anaconda\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Using cached transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "Installing collected packages: transformers\n",
      "Successfully installed transformers-4.44.2\n",
      "Error: Failed to import transformers.models.mistral.modeling_mistral because of the following error (look up to see its traceback):\n",
      "cannot import name 'SlidingWindowCache' from 'transformers.cache_utils' (C:\\Users\\sahil\\anaconda\\Lib\\site-packages\\transformers\\cache_utils.py)\n"
     ]
    }
   ],
   "source": [
    "# Update transformers and related dependencies\n",
    "!pip install --upgrade transformers torch pillow\n",
    "\n",
    "# Reinstall transformers if needed\n",
    "!pip uninstall -y transformers\n",
    "!pip install transformers\n",
    "\n",
    "# Verify installation\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "try:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "    print(\"Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d06a3107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\sahil\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Replace 'your_token_here' with your actual Hugging Face token\n",
    "token = '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'\n",
    "login(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "229d442c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GPTModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Replace this with the actual retrieved context from your RAG pipeline\u001b[39;00m\n\u001b[0;32m      9\u001b[0m retrieval_context \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll customers are eligible for a 30 day full refund at no extra cost.\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 11\u001b[0m metric \u001b[38;5;241m=\u001b[39m FaithfulnessMetric(\n\u001b[0;32m     12\u001b[0m     threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[0;32m     13\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     14\u001b[0m     include_reason\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     16\u001b[0m test_case \u001b[38;5;241m=\u001b[39m LLMTestCase(\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat if these shoes don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt fit?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m     actual_output\u001b[38;5;241m=\u001b[39mactual_output,\n\u001b[0;32m     19\u001b[0m     retrieval_context\u001b[38;5;241m=\u001b[39mretrieval_context\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     22\u001b[0m metric\u001b[38;5;241m.\u001b[39mmeasure(test_case)\n",
      "File \u001b[1;32m~\\Downloads\\custom_metrics\\faithfulness.py:40\u001b[0m, in \u001b[0;36mFaithfulnessMetric.__init__\u001b[1;34m(self, threshold, model, include_reason, async_mode, strict_mode, verbose_mode)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     32\u001b[0m     threshold: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     verbose_mode: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     38\u001b[0m ):\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m strict_mode \u001b[38;5;28;01melse\u001b[39;00m threshold\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musing_native_model \u001b[38;5;241m=\u001b[39m initialize_model(model)\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_model_name()\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_reason \u001b[38;5;241m=\u001b[39m include_reason\n",
      "File \u001b[1;32m~\\Downloads\\custom_metrics\\utils.py:148\u001b[0m, in \u001b[0;36minitialize_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03mReturns a tuple of (initialized DeepEvalBaseLLM, using_native_model boolean)\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# If model is a GPTModel, it should be deemed as using native model\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, GPTModel):\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# If model is a DeepEvalBaseLLM but not a GPTModel, we can not assume it is a native model\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GPTModel' is not defined"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "from faithfulness import FaithfulnessMetric\n",
    "from test_case import LLMTestCase\n",
    "\n",
    "# Replace this with the actual output from your LLM application\n",
    "actual_output = \"We offer a 30-day full refund at no extra cost.\"\n",
    "\n",
    "# Replace this with the actual retrieved context from your RAG pipeline\n",
    "retrieval_context = [\"All customers are eligible for a 30 day full refund at no extra cost.\"]\n",
    "\n",
    "metric = FaithfulnessMetric(\n",
    "    threshold=0.7,\n",
    "    model=model,\n",
    "    include_reason=True\n",
    ")\n",
    "test_case = LLMTestCase(\n",
    "    input=\"What if these shoes don't fit?\",\n",
    "    actual_output=actual_output,\n",
    "    retrieval_context=retrieval_context\n",
    ")\n",
    "\n",
    "metric.measure(test_case)\n",
    "print(metric.score)\n",
    "print(metric.reason)\n",
    "\n",
    "# or evaluate test cases in bulk\n",
    "evaluate([test_case], [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b95a827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
